{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORvwib-YSR-p"
      },
      "source": [
        "CIFAR10 - DenseNet solution. AdaptaciÃ³n de https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/applications/densenet.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YRXPjE-Sf1a"
      },
      "source": [
        "Install Keras just in case..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhsFJNHpSSKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72e81b2c-7fc6-4d11-907d-701704081efa"
      },
      "source": [
        "!pip3 install keras\n",
        "!pip3 install keras_applications"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n",
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (3.1.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGX8RGwHSSTr"
      },
      "source": [
        "Imports..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8qeBuPiSSdc"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "\n",
        "import warnings\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Flatten, Input, Conv2D, Add, ZeroPadding2D, Dense, Dropout, Activation, Reshape, Conv2DTranspose, UpSampling2D, MaxPooling2D, AveragePooling2D, GlobalMaxPooling2D, concatenate\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.merge import add\n",
        "from keras import Model\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras.regularizers import l2\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras.applications.imagenet_utils import preprocess_input as _preprocess_input\n",
        "import keras.backend as K\n",
        "from keras.engine.topology import get_source_inputs\n",
        "from keras import utils\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler as LRS\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "import keras"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M9uBGifSSqd"
      },
      "source": [
        "Define batch size, number of epochs and number of classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaWFWm8mSTBj"
      },
      "source": [
        "batch_size = 100\n",
        "num_classes = 10\n",
        "epochs = 75"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuM-ZML22Cn9",
        "outputId": "1eea45b7-2e70-4ef5-9ba4-0ad60f74767b"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0CgF6jTejyx"
      },
      "source": [
        "## Data Augmentation with an ImageGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.3,\n",
        "    rotation_range=45,\n",
        "    vertical_flip=False)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdaMLtdhtd5j"
      },
      "source": [
        "Movidas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap_0BFfhRKEC"
      },
      "source": [
        "def __conv_block(ip, nb_filter, bottleneck=False, dropout_rate=None,\n",
        "                 weight_decay=1e-4, block_prefix=None):\n",
        "    '''\n",
        "    Adds a convolution layer (with batch normalization and relu),\n",
        "    and optionally a bottleneck layer.\n",
        "    # Arguments\n",
        "        ip: Input tensor\n",
        "        nb_filter: integer, the dimensionality of the output space\n",
        "            (i.e. the number output of filters in the convolution)\n",
        "        bottleneck: if True, adds a bottleneck convolution block\n",
        "        dropout_rate: dropout rate\n",
        "        weight_decay: weight decay factor\n",
        "        block_prefix: str, for unique layer naming\n",
        "     # Input shape\n",
        "        4D tensor with shape:\n",
        "        `(samples, channels, rows, cols)` if data_format='channels_first'\n",
        "        or 4D tensor with shape:\n",
        "        `(samples, rows, cols, channels)` if data_format='channels_last'.\n",
        "    # Output shape\n",
        "        4D tensor with shape:\n",
        "        `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n",
        "        or 4D tensor with shape:\n",
        "        `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n",
        "        `rows` and `cols` values might have changed due to stride.\n",
        "    # Returns\n",
        "        output tensor of block\n",
        "    '''\n",
        "    with K.name_scope('ConvBlock'):\n",
        "        concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5,\n",
        "                               name=name_or_none(block_prefix, '_bn'))(ip)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        if bottleneck:\n",
        "            inter_channel = nb_filter * 4\n",
        "\n",
        "            x = Conv2D(inter_channel, (1, 1), kernel_initializer='he_normal',\n",
        "                       padding='same', use_bias=False,\n",
        "                       kernel_regularizer=l2(weight_decay),\n",
        "                       name=name_or_none(block_prefix, '_bottleneck_conv2D'))(x)\n",
        "            x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5,\n",
        "                                   name=name_or_none(block_prefix, '_bottleneck_bn'))(x)\n",
        "            x = Activation('relu')(x)\n",
        "\n",
        "        x = Conv2D(nb_filter, (3, 3), kernel_initializer='he_normal', padding='same',\n",
        "                   use_bias=False, name=name_or_none(block_prefix, '_conv2D'))(x)\n",
        "        if dropout_rate:\n",
        "            x = Dropout(dropout_rate)(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwkmg_n-Rssm"
      },
      "source": [
        "def __dense_block(x, nb_layers, nb_filter, growth_rate, bottleneck=False,\n",
        "                  dropout_rate=None, weight_decay=1e-4, grow_nb_filters=True,\n",
        "                  return_concat_list=False, block_prefix=None):\n",
        "    '''\n",
        "    Build a dense_block where the output of each conv_block is fed\n",
        "    to subsequent ones\n",
        "    # Arguments\n",
        "        x: input keras tensor\n",
        "        nb_layers: the number of conv_blocks to append to the model\n",
        "        nb_filter: integer, the dimensionality of the output space\n",
        "            (i.e. the number output of filters in the convolution)\n",
        "        growth_rate: growth rate of the dense block\n",
        "        bottleneck: if True, adds a bottleneck convolution block to\n",
        "            each conv_block\n",
        "        dropout_rate: dropout rate\n",
        "        weight_decay: weight decay factor\n",
        "        grow_nb_filters: if True, allows number of filters to grow\n",
        "        return_concat_list: set to True to return the list of\n",
        "            feature maps along with the actual output\n",
        "        block_prefix: str, for block unique naming\n",
        "    # Return\n",
        "        If return_concat_list is True, returns a list of the output\n",
        "        keras tensor, the number of filters and a list of all the\n",
        "        dense blocks added to the keras tensor\n",
        "        If return_concat_list is False, returns a list of the output\n",
        "        keras tensor and the number of filters\n",
        "    '''\n",
        "    with K.name_scope('DenseBlock'):\n",
        "        concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "        x_list = [x]\n",
        "\n",
        "        for i in range(nb_layers):\n",
        "            cb = __conv_block(x, growth_rate, bottleneck, dropout_rate, weight_decay,\n",
        "                              block_prefix=name_or_none(block_prefix, '_%i' % i))\n",
        "            x_list.append(cb)\n",
        "\n",
        "            x = concatenate([x, cb], axis=concat_axis)\n",
        "\n",
        "            if grow_nb_filters:\n",
        "                nb_filter += growth_rate\n",
        "\n",
        "        if return_concat_list:\n",
        "            return x, nb_filter, x_list\n",
        "        else:\n",
        "            return x, nb_filter"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt9-YGpZRtoj"
      },
      "source": [
        "def __transition_block(ip, nb_filter, compression=1.0, weight_decay=1e-4,\n",
        "                       block_prefix=None, transition_pooling='max'):\n",
        "    '''\n",
        "    Adds a pointwise convolution layer (with batch normalization and relu),\n",
        "    and an average pooling layer. The number of output convolution filters\n",
        "    can be reduced by appropriately reducing the compression parameter.\n",
        "    # Arguments\n",
        "        ip: input keras tensor\n",
        "        nb_filter: integer, the dimensionality of the output space\n",
        "            (i.e. the number output of filters in the convolution)\n",
        "        compression: calculated as 1 - reduction. Reduces the number\n",
        "            of feature maps in the transition block.\n",
        "        weight_decay: weight decay factor\n",
        "        block_prefix: str, for block unique naming\n",
        "    # Input shape\n",
        "        4D tensor with shape:\n",
        "        `(samples, channels, rows, cols)` if data_format='channels_first'\n",
        "        or 4D tensor with shape:\n",
        "        `(samples, rows, cols, channels)` if data_format='channels_last'.\n",
        "    # Output shape\n",
        "        4D tensor with shape:\n",
        "        `(samples, nb_filter * compression, rows / 2, cols / 2)`\n",
        "        if data_format='channels_first'\n",
        "        or 4D tensor with shape:\n",
        "        `(samples, rows / 2, cols / 2, nb_filter * compression)`\n",
        "        if data_format='channels_last'.\n",
        "    # Returns\n",
        "        a keras tensor\n",
        "    '''\n",
        "    with K.name_scope('Transition'):\n",
        "        concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5,\n",
        "                               name=name_or_none(block_prefix, '_bn'))(ip)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2D(int(nb_filter * compression), (1, 1), kernel_initializer='he_normal',\n",
        "                   padding='same', use_bias=False, kernel_regularizer=l2(weight_decay),\n",
        "                   name=name_or_none(block_prefix, '_conv2D'))(x)\n",
        "        if transition_pooling == 'avg':\n",
        "            x = AveragePooling2D((2, 2), strides=(2, 2))(x)\n",
        "        elif transition_pooling == 'max':\n",
        "            x = MaxPooling2D((2, 2), strides=(2, 2))(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pbEvFvxf5z_"
      },
      "source": [
        "def __transition_up_block(ip, nb_filters, type='deconv', weight_decay=1E-4,\n",
        "                          block_prefix=None):\n",
        "    '''Adds an upsampling block. Upsampling operation relies on the the type parameter.\n",
        "    # Arguments\n",
        "        ip: input keras tensor\n",
        "        nb_filters: integer, the dimensionality of the output space\n",
        "            (i.e. the number output of filters in the convolution)\n",
        "        type: can be 'upsampling', 'subpixel', 'deconv'. Determines\n",
        "            type of upsampling performed\n",
        "        weight_decay: weight decay factor\n",
        "        block_prefix: str, for block unique naming\n",
        "    # Input shape\n",
        "        4D tensor with shape:\n",
        "        `(samples, channels, rows, cols)` if data_format='channels_first'\n",
        "        or 4D tensor with shape:\n",
        "        `(samples, rows, cols, channels)` if data_format='channels_last'.\n",
        "    # Output shape\n",
        "        4D tensor with shape:\n",
        "        `(samples, nb_filter, rows * 2, cols * 2)` if data_format='channels_first'\n",
        "        or 4D tensor with shape:\n",
        "        `(samples, rows * 2, cols * 2, nb_filter)` if data_format='channels_last'.\n",
        "    # Returns\n",
        "        a keras tensor\n",
        "    '''\n",
        "    with K.name_scope('TransitionUp'):\n",
        "\n",
        "        if type == 'upsampling':\n",
        "            x = UpSampling2D(name=name_or_none(block_prefix, '_upsampling'))(ip)\n",
        "        elif type == 'subpixel':\n",
        "            x = Conv2D(nb_filters, (3, 3), activation='relu', padding='same',\n",
        "                       kernel_regularizer=l2(weight_decay), use_bias=False,\n",
        "                       kernel_initializer='he_normal',\n",
        "                       name=name_or_none(block_prefix, '_conv2D'))(ip)\n",
        "            x = SubPixelUpscaling(scale_factor=2,\n",
        "                                  name=name_or_none(block_prefix, '_subpixel'))(x)\n",
        "            x = Conv2D(nb_filters, (3, 3), activation='relu', padding='same',\n",
        "                       kernel_regularizer=l2(weight_decay), use_bias=False,\n",
        "                       kernel_initializer='he_normal',\n",
        "                       name=name_or_none(block_prefix, '_conv2D'))(x)\n",
        "        else:\n",
        "            x = Conv2DTranspose(nb_filters, (3, 3), activation='relu', padding='same',\n",
        "                                strides=(2, 2), kernel_initializer='he_normal',\n",
        "                                kernel_regularizer=l2(weight_decay),\n",
        "                                name=name_or_none(block_prefix, '_conv2DT'))(ip)\n",
        "        return x"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9L_jJ0ff5_s"
      },
      "source": [
        "def __create_dense_net(nb_classes, img_input, include_top, depth=40, nb_dense_block=3,\n",
        "                       growth_rate=12, nb_filter=-1, nb_layers_per_block=-1,\n",
        "                       bottleneck=False, reduction=0.0, dropout_rate=None,\n",
        "                       weight_decay=1e-4, subsample_initial_block=False, pooling=None,\n",
        "                       activation='softmax', transition_pooling='avg'):\n",
        "    ''' Build the DenseNet model\n",
        "    # Arguments\n",
        "        nb_classes: number of classes\n",
        "        img_input: tuple of shape (channels, rows, columns) or (rows, columns, channels)\n",
        "        include_top: flag to include the final Dense layer\n",
        "        depth: number or layers\n",
        "        nb_dense_block: number of dense blocks to add to end (generally = 3)\n",
        "        growth_rate: number of filters to add per dense block\n",
        "        nb_filter: initial number of filters. Default -1 indicates initial number\n",
        "            of filters is 2 * growth_rate\n",
        "        nb_layers_per_block: number of layers in each dense block.\n",
        "                Can be a -1, positive integer or a list.\n",
        "                If -1, calculates nb_layer_per_block from the depth of the network.\n",
        "                If positive integer, a set number of layers per dense block.\n",
        "                If list, nb_layer is used as provided. Note that list size must\n",
        "                be (nb_dense_block + 1)\n",
        "        bottleneck: add bottleneck blocks\n",
        "        reduction: reduction factor of transition blocks. Note : reduction value is\n",
        "            inverted to compute compression\n",
        "        dropout_rate: dropout rate\n",
        "        weight_decay: weight decay rate\n",
        "        subsample_initial_block: Changes model type to suit different datasets.\n",
        "            Should be set to True for ImageNet, and False for CIFAR datasets.\n",
        "            When set to True, the initial convolution will be strided and\n",
        "            adds a MaxPooling2D before the initial dense block.\n",
        "        pooling: Optional pooling mode for feature extraction\n",
        "            when `include_top` is `False`.\n",
        "            - `None` means that the output of the model\n",
        "                will be the 4D tensor output of the\n",
        "                last convolutional layer.\n",
        "            - `avg` means that global average pooling\n",
        "                will be applied to the output of the\n",
        "                last convolutional layer, and thus\n",
        "                the output of the model will be a\n",
        "                2D tensor.\n",
        "            - `max` means that global max pooling will\n",
        "                be applied.\n",
        "        activation: Type of activation at the top layer. Can be one of 'softmax' or\n",
        "            'sigmoid'. Note that if sigmoid is used, classes must be 1.\n",
        "        transition_pooling: `avg` for avg pooling (default), `max` for max pooling,\n",
        "            None for no pooling during scale transition blocks. Please note that this\n",
        "            default differs from the DenseNetFCN paper in accordance with the DenseNet\n",
        "            paper.\n",
        "    # Returns\n",
        "        a keras tensor\n",
        "    # Raises\n",
        "        ValueError: in case of invalid argument for `reduction`\n",
        "            or `nb_dense_block`\n",
        "    '''\n",
        "    with K.name_scope('DenseNet'):\n",
        "        concat_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "        if reduction != 0.0:\n",
        "            if not (reduction <= 1.0 and reduction > 0.0):\n",
        "                raise ValueError('`reduction` value must lie between 0.0 and 1.0')\n",
        "\n",
        "        # layers in each dense block\n",
        "        if type(nb_layers_per_block) is list or type(nb_layers_per_block) is tuple:\n",
        "            nb_layers = list(nb_layers_per_block)  # Convert tuple to list\n",
        "\n",
        "            if len(nb_layers) != nb_dense_block:\n",
        "                raise ValueError('If `nb_dense_block` is a list, its length must match '\n",
        "                                 'the number of layers provided by `nb_layers`.')\n",
        "\n",
        "            final_nb_layer = nb_layers[-1]\n",
        "            nb_layers = nb_layers[:-1]\n",
        "        else:\n",
        "            if nb_layers_per_block == -1:\n",
        "                assert (depth - 4) % 3 == 0, ('Depth must be 3 N + 4 '\n",
        "                                              'if nb_layers_per_block == -1')\n",
        "                count = int((depth - 4) / 3)\n",
        "\n",
        "                if bottleneck:\n",
        "                    count = count // 2\n",
        "\n",
        "                nb_layers = [count for _ in range(nb_dense_block)]\n",
        "                final_nb_layer = count\n",
        "            else:\n",
        "                final_nb_layer = nb_layers_per_block\n",
        "                nb_layers = [nb_layers_per_block] * nb_dense_block\n",
        "\n",
        "        # compute initial nb_filter if -1, else accept users initial nb_filter\n",
        "        if nb_filter <= 0:\n",
        "            nb_filter = 2 * growth_rate\n",
        "\n",
        "        # compute compression factor\n",
        "        compression = 1.0 - reduction\n",
        "\n",
        "        # Initial convolution\n",
        "        if subsample_initial_block:\n",
        "            initial_kernel = (7, 7)\n",
        "            initial_strides = (2, 2)\n",
        "        else:\n",
        "            initial_kernel = (3, 3)\n",
        "            initial_strides = (1, 1)\n",
        "\n",
        "        x = Conv2D(nb_filter, initial_kernel, kernel_initializer='he_normal',\n",
        "                   padding='same', name='initial_conv2D', strides=initial_strides,\n",
        "                   use_bias=False, kernel_regularizer=l2(weight_decay))(img_input)\n",
        "\n",
        "        if subsample_initial_block:\n",
        "            x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5,\n",
        "                                   name='initial_bn')(x)\n",
        "            x = Activation('relu')(x)\n",
        "            x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n",
        "\n",
        "        # Add dense blocks\n",
        "        for block_idx in range(nb_dense_block - 1):\n",
        "            x, nb_filter = __dense_block(x, nb_layers[block_idx], nb_filter,\n",
        "                                         growth_rate, bottleneck=bottleneck,\n",
        "                                         dropout_rate=dropout_rate,\n",
        "                                         weight_decay=weight_decay,\n",
        "                                         block_prefix='dense_%i' % block_idx)\n",
        "            # add transition_block\n",
        "            x = __transition_block(x, nb_filter, compression=compression,\n",
        "                                   weight_decay=weight_decay,\n",
        "                                   block_prefix='tr_%i' % block_idx,\n",
        "                                   transition_pooling=transition_pooling)\n",
        "            nb_filter = int(nb_filter * compression)\n",
        "\n",
        "        # The last dense_block does not have a transition_block\n",
        "        x, nb_filter = __dense_block(x, final_nb_layer, nb_filter, growth_rate,\n",
        "                                     bottleneck=bottleneck, dropout_rate=dropout_rate,\n",
        "                                     weight_decay=weight_decay,\n",
        "                                     block_prefix='dense_%i' % (nb_dense_block - 1))\n",
        "\n",
        "        x = BatchNormalization(axis=concat_axis, epsilon=1.1e-5, name='final_bn')(x)\n",
        "        x = Activation('relu')(x)\n",
        "\n",
        "        if include_top:\n",
        "            if pooling == 'avg':\n",
        "                x = GlobalAveragePooling2D()(x)\n",
        "            elif pooling == 'max':\n",
        "                x = GlobalMaxPooling2D()(x)\n",
        "            x = Dense(nb_classes, activation=activation)(x)\n",
        "        else:\n",
        "            if pooling == 'avg':\n",
        "                x = GlobalAveragePooling2D()(x)\n",
        "            elif pooling == 'max':\n",
        "                x = GlobalMaxPooling2D()(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCWB7VOgZ8SZ"
      },
      "source": [
        "def name_or_none(prefix, name):\n",
        "    return prefix + name if (prefix is not None and name is not None) else None"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF5v2bpcwZCy",
        "outputId": "ba2eed56-1e67-4700-f323-fe56deec0827"
      },
      "source": [
        "input_shape = x_train.shape[1:]\n",
        "input_shape = _obtain_input_shape(input_shape,\n",
        "                                  default_size=224,\n",
        "                                  min_size=32,\n",
        "                                  data_format=K.image_data_format(),\n",
        "                                  require_flatten=True,\n",
        "                                  weights=None)\n",
        "img_input = Input(shape=input_shape)\n",
        "x = __create_dense_net(num_classes, img_input, True)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(num_classes)(x)\n",
        "x = Activation('softmax')(x)\n",
        "\n",
        "model = Model(get_source_inputs(img_input), x, name='densenet')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"densenet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "initial_conv2D (Conv2D)         (None, 32, 32, 24)   648         input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_0_bn (BatchNormalizatio (None, 32, 32, 24)   96          initial_conv2D[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 32, 32, 24)   0           dense_0_0_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_0_conv2D (Conv2D)       (None, 32, 32, 12)   2592        activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_144 (Concatenate)   (None, 32, 32, 36)   0           initial_conv2D[0][0]             \n",
            "                                                                 dense_0_0_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_1_bn (BatchNormalizatio (None, 32, 32, 36)   144         concatenate_144[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 32, 32, 36)   0           dense_0_1_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_1_conv2D (Conv2D)       (None, 32, 32, 12)   3888        activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_145 (Concatenate)   (None, 32, 32, 48)   0           concatenate_144[0][0]            \n",
            "                                                                 dense_0_1_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_2_bn (BatchNormalizatio (None, 32, 32, 48)   192         concatenate_145[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 32, 32, 48)   0           dense_0_2_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_2_conv2D (Conv2D)       (None, 32, 32, 12)   5184        activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_146 (Concatenate)   (None, 32, 32, 60)   0           concatenate_145[0][0]            \n",
            "                                                                 dense_0_2_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_3_bn (BatchNormalizatio (None, 32, 32, 60)   240         concatenate_146[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_161 (Activation)     (None, 32, 32, 60)   0           dense_0_3_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_3_conv2D (Conv2D)       (None, 32, 32, 12)   6480        activation_161[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_147 (Concatenate)   (None, 32, 32, 72)   0           concatenate_146[0][0]            \n",
            "                                                                 dense_0_3_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_4_bn (BatchNormalizatio (None, 32, 32, 72)   288         concatenate_147[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_162 (Activation)     (None, 32, 32, 72)   0           dense_0_4_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_4_conv2D (Conv2D)       (None, 32, 32, 12)   7776        activation_162[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_148 (Concatenate)   (None, 32, 32, 84)   0           concatenate_147[0][0]            \n",
            "                                                                 dense_0_4_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_5_bn (BatchNormalizatio (None, 32, 32, 84)   336         concatenate_148[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_163 (Activation)     (None, 32, 32, 84)   0           dense_0_5_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_5_conv2D (Conv2D)       (None, 32, 32, 12)   9072        activation_163[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_149 (Concatenate)   (None, 32, 32, 96)   0           concatenate_148[0][0]            \n",
            "                                                                 dense_0_5_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_6_bn (BatchNormalizatio (None, 32, 32, 96)   384         concatenate_149[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_164 (Activation)     (None, 32, 32, 96)   0           dense_0_6_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_6_conv2D (Conv2D)       (None, 32, 32, 12)   10368       activation_164[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_150 (Concatenate)   (None, 32, 32, 108)  0           concatenate_149[0][0]            \n",
            "                                                                 dense_0_6_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_7_bn (BatchNormalizatio (None, 32, 32, 108)  432         concatenate_150[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_165 (Activation)     (None, 32, 32, 108)  0           dense_0_7_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_7_conv2D (Conv2D)       (None, 32, 32, 12)   11664       activation_165[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_151 (Concatenate)   (None, 32, 32, 120)  0           concatenate_150[0][0]            \n",
            "                                                                 dense_0_7_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_8_bn (BatchNormalizatio (None, 32, 32, 120)  480         concatenate_151[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_166 (Activation)     (None, 32, 32, 120)  0           dense_0_8_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_8_conv2D (Conv2D)       (None, 32, 32, 12)   12960       activation_166[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_152 (Concatenate)   (None, 32, 32, 132)  0           concatenate_151[0][0]            \n",
            "                                                                 dense_0_8_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_9_bn (BatchNormalizatio (None, 32, 32, 132)  528         concatenate_152[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_167 (Activation)     (None, 32, 32, 132)  0           dense_0_9_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_9_conv2D (Conv2D)       (None, 32, 32, 12)   14256       activation_167[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_153 (Concatenate)   (None, 32, 32, 144)  0           concatenate_152[0][0]            \n",
            "                                                                 dense_0_9_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_10_bn (BatchNormalizati (None, 32, 32, 144)  576         concatenate_153[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_168 (Activation)     (None, 32, 32, 144)  0           dense_0_10_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_10_conv2D (Conv2D)      (None, 32, 32, 12)   15552       activation_168[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_154 (Concatenate)   (None, 32, 32, 156)  0           concatenate_153[0][0]            \n",
            "                                                                 dense_0_10_conv2D[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_11_bn (BatchNormalizati (None, 32, 32, 156)  624         concatenate_154[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_169 (Activation)     (None, 32, 32, 156)  0           dense_0_11_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_0_11_conv2D (Conv2D)      (None, 32, 32, 12)   16848       activation_169[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_155 (Concatenate)   (None, 32, 32, 168)  0           concatenate_154[0][0]            \n",
            "                                                                 dense_0_11_conv2D[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tr_0_bn (BatchNormalization)    (None, 32, 32, 168)  672         concatenate_155[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_170 (Activation)     (None, 32, 32, 168)  0           tr_0_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tr_0_conv2D (Conv2D)            (None, 32, 32, 168)  28224       activation_170[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 16, 16, 168)  0           tr_0_conv2D[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_0_bn (BatchNormalizatio (None, 16, 16, 168)  672         average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_171 (Activation)     (None, 16, 16, 168)  0           dense_1_0_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_0_conv2D (Conv2D)       (None, 16, 16, 12)   18144       activation_171[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_156 (Concatenate)   (None, 16, 16, 180)  0           average_pooling2d_8[0][0]        \n",
            "                                                                 dense_1_0_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_1_bn (BatchNormalizatio (None, 16, 16, 180)  720         concatenate_156[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_172 (Activation)     (None, 16, 16, 180)  0           dense_1_1_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_1_conv2D (Conv2D)       (None, 16, 16, 12)   19440       activation_172[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_157 (Concatenate)   (None, 16, 16, 192)  0           concatenate_156[0][0]            \n",
            "                                                                 dense_1_1_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_2_bn (BatchNormalizatio (None, 16, 16, 192)  768         concatenate_157[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_173 (Activation)     (None, 16, 16, 192)  0           dense_1_2_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_2_conv2D (Conv2D)       (None, 16, 16, 12)   20736       activation_173[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_158 (Concatenate)   (None, 16, 16, 204)  0           concatenate_157[0][0]            \n",
            "                                                                 dense_1_2_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_3_bn (BatchNormalizatio (None, 16, 16, 204)  816         concatenate_158[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_174 (Activation)     (None, 16, 16, 204)  0           dense_1_3_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_3_conv2D (Conv2D)       (None, 16, 16, 12)   22032       activation_174[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_159 (Concatenate)   (None, 16, 16, 216)  0           concatenate_158[0][0]            \n",
            "                                                                 dense_1_3_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_4_bn (BatchNormalizatio (None, 16, 16, 216)  864         concatenate_159[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_175 (Activation)     (None, 16, 16, 216)  0           dense_1_4_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_4_conv2D (Conv2D)       (None, 16, 16, 12)   23328       activation_175[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_160 (Concatenate)   (None, 16, 16, 228)  0           concatenate_159[0][0]            \n",
            "                                                                 dense_1_4_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_5_bn (BatchNormalizatio (None, 16, 16, 228)  912         concatenate_160[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_176 (Activation)     (None, 16, 16, 228)  0           dense_1_5_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_5_conv2D (Conv2D)       (None, 16, 16, 12)   24624       activation_176[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_161 (Concatenate)   (None, 16, 16, 240)  0           concatenate_160[0][0]            \n",
            "                                                                 dense_1_5_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_6_bn (BatchNormalizatio (None, 16, 16, 240)  960         concatenate_161[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_177 (Activation)     (None, 16, 16, 240)  0           dense_1_6_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_6_conv2D (Conv2D)       (None, 16, 16, 12)   25920       activation_177[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_162 (Concatenate)   (None, 16, 16, 252)  0           concatenate_161[0][0]            \n",
            "                                                                 dense_1_6_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_7_bn (BatchNormalizatio (None, 16, 16, 252)  1008        concatenate_162[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_178 (Activation)     (None, 16, 16, 252)  0           dense_1_7_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_7_conv2D (Conv2D)       (None, 16, 16, 12)   27216       activation_178[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_163 (Concatenate)   (None, 16, 16, 264)  0           concatenate_162[0][0]            \n",
            "                                                                 dense_1_7_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_8_bn (BatchNormalizatio (None, 16, 16, 264)  1056        concatenate_163[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_179 (Activation)     (None, 16, 16, 264)  0           dense_1_8_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_8_conv2D (Conv2D)       (None, 16, 16, 12)   28512       activation_179[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_164 (Concatenate)   (None, 16, 16, 276)  0           concatenate_163[0][0]            \n",
            "                                                                 dense_1_8_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_9_bn (BatchNormalizatio (None, 16, 16, 276)  1104        concatenate_164[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_180 (Activation)     (None, 16, 16, 276)  0           dense_1_9_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_9_conv2D (Conv2D)       (None, 16, 16, 12)   29808       activation_180[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_165 (Concatenate)   (None, 16, 16, 288)  0           concatenate_164[0][0]            \n",
            "                                                                 dense_1_9_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_10_bn (BatchNormalizati (None, 16, 16, 288)  1152        concatenate_165[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_181 (Activation)     (None, 16, 16, 288)  0           dense_1_10_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_10_conv2D (Conv2D)      (None, 16, 16, 12)   31104       activation_181[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_166 (Concatenate)   (None, 16, 16, 300)  0           concatenate_165[0][0]            \n",
            "                                                                 dense_1_10_conv2D[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_11_bn (BatchNormalizati (None, 16, 16, 300)  1200        concatenate_166[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_182 (Activation)     (None, 16, 16, 300)  0           dense_1_11_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1_11_conv2D (Conv2D)      (None, 16, 16, 12)   32400       activation_182[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_167 (Concatenate)   (None, 16, 16, 312)  0           concatenate_166[0][0]            \n",
            "                                                                 dense_1_11_conv2D[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "tr_1_bn (BatchNormalization)    (None, 16, 16, 312)  1248        concatenate_167[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_183 (Activation)     (None, 16, 16, 312)  0           tr_1_bn[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tr_1_conv2D (Conv2D)            (None, 16, 16, 312)  97344       activation_183[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 8, 8, 312)    0           tr_1_conv2D[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_0_bn (BatchNormalizatio (None, 8, 8, 312)    1248        average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_184 (Activation)     (None, 8, 8, 312)    0           dense_2_0_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_0_conv2D (Conv2D)       (None, 8, 8, 12)     33696       activation_184[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_168 (Concatenate)   (None, 8, 8, 324)    0           average_pooling2d_9[0][0]        \n",
            "                                                                 dense_2_0_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_1_bn (BatchNormalizatio (None, 8, 8, 324)    1296        concatenate_168[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_185 (Activation)     (None, 8, 8, 324)    0           dense_2_1_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_1_conv2D (Conv2D)       (None, 8, 8, 12)     34992       activation_185[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_169 (Concatenate)   (None, 8, 8, 336)    0           concatenate_168[0][0]            \n",
            "                                                                 dense_2_1_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_2_bn (BatchNormalizatio (None, 8, 8, 336)    1344        concatenate_169[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_186 (Activation)     (None, 8, 8, 336)    0           dense_2_2_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_2_conv2D (Conv2D)       (None, 8, 8, 12)     36288       activation_186[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_170 (Concatenate)   (None, 8, 8, 348)    0           concatenate_169[0][0]            \n",
            "                                                                 dense_2_2_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_3_bn (BatchNormalizatio (None, 8, 8, 348)    1392        concatenate_170[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_187 (Activation)     (None, 8, 8, 348)    0           dense_2_3_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_3_conv2D (Conv2D)       (None, 8, 8, 12)     37584       activation_187[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_171 (Concatenate)   (None, 8, 8, 360)    0           concatenate_170[0][0]            \n",
            "                                                                 dense_2_3_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_4_bn (BatchNormalizatio (None, 8, 8, 360)    1440        concatenate_171[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_188 (Activation)     (None, 8, 8, 360)    0           dense_2_4_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_4_conv2D (Conv2D)       (None, 8, 8, 12)     38880       activation_188[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_172 (Concatenate)   (None, 8, 8, 372)    0           concatenate_171[0][0]            \n",
            "                                                                 dense_2_4_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_5_bn (BatchNormalizatio (None, 8, 8, 372)    1488        concatenate_172[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_189 (Activation)     (None, 8, 8, 372)    0           dense_2_5_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_5_conv2D (Conv2D)       (None, 8, 8, 12)     40176       activation_189[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_173 (Concatenate)   (None, 8, 8, 384)    0           concatenate_172[0][0]            \n",
            "                                                                 dense_2_5_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_6_bn (BatchNormalizatio (None, 8, 8, 384)    1536        concatenate_173[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_190 (Activation)     (None, 8, 8, 384)    0           dense_2_6_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_6_conv2D (Conv2D)       (None, 8, 8, 12)     41472       activation_190[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_174 (Concatenate)   (None, 8, 8, 396)    0           concatenate_173[0][0]            \n",
            "                                                                 dense_2_6_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_7_bn (BatchNormalizatio (None, 8, 8, 396)    1584        concatenate_174[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_191 (Activation)     (None, 8, 8, 396)    0           dense_2_7_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_7_conv2D (Conv2D)       (None, 8, 8, 12)     42768       activation_191[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_175 (Concatenate)   (None, 8, 8, 408)    0           concatenate_174[0][0]            \n",
            "                                                                 dense_2_7_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_8_bn (BatchNormalizatio (None, 8, 8, 408)    1632        concatenate_175[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_192 (Activation)     (None, 8, 8, 408)    0           dense_2_8_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_8_conv2D (Conv2D)       (None, 8, 8, 12)     44064       activation_192[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_176 (Concatenate)   (None, 8, 8, 420)    0           concatenate_175[0][0]            \n",
            "                                                                 dense_2_8_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_9_bn (BatchNormalizatio (None, 8, 8, 420)    1680        concatenate_176[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_193 (Activation)     (None, 8, 8, 420)    0           dense_2_9_bn[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_9_conv2D (Conv2D)       (None, 8, 8, 12)     45360       activation_193[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_177 (Concatenate)   (None, 8, 8, 432)    0           concatenate_176[0][0]            \n",
            "                                                                 dense_2_9_conv2D[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_10_bn (BatchNormalizati (None, 8, 8, 432)    1728        concatenate_177[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_194 (Activation)     (None, 8, 8, 432)    0           dense_2_10_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_10_conv2D (Conv2D)      (None, 8, 8, 12)     46656       activation_194[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_178 (Concatenate)   (None, 8, 8, 444)    0           concatenate_177[0][0]            \n",
            "                                                                 dense_2_10_conv2D[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_11_bn (BatchNormalizati (None, 8, 8, 444)    1776        concatenate_178[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_195 (Activation)     (None, 8, 8, 444)    0           dense_2_11_bn[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2_11_conv2D (Conv2D)      (None, 8, 8, 12)     47952       activation_195[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_179 (Concatenate)   (None, 8, 8, 456)    0           concatenate_178[0][0]            \n",
            "                                                                 dense_2_11_conv2D[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "final_bn (BatchNormalization)   (None, 8, 8, 456)    1824        concatenate_179[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "activation_196 (Activation)     (None, 8, 8, 456)    0           final_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 8, 8, 10)     4570        activation_196[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 640)          0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 10)           6410        flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_197 (Activation)     (None, 10)           0           dense_7[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 1,084,428\n",
            "Trainable params: 1,065,708\n",
            "Non-trainable params: 18,720\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkDjl8exTTDZ"
      },
      "source": [
        "Define an optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTRuAT1FTTOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0fa39e3-e944-4f8c-cb89-4506a4ab91a2"
      },
      "source": [
        "opt = SGD(lr=0.1, decay=1e-6)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmhjZqVhfV18"
      },
      "source": [
        "DEFINE A LEARNING RATE SCHEDULER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjGe1KAwfV7F"
      },
      "source": [
        "def scheduler(epoch):\n",
        "    if epoch < 25:\n",
        "        return .1\n",
        "    elif epoch < 50:\n",
        "        return 0.01\n",
        "    else:\n",
        "        return 0.001\n",
        "\n",
        "# Callbacks\n",
        "set_lr = LRS(scheduler)\n",
        "es = keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHhBHWFjTTYy"
      },
      "source": [
        "Compile the model, define loss and link the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W8KCPtcTTii"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBOKdV6MTTtA"
      },
      "source": [
        "Finally, train the model and evaluate over the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLPsSdVDTT37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "503ee7e2-2df5-4a6f-bae0-c2fbc16f927a"
      },
      "source": [
        "history=model.fit(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                  steps_per_epoch=len(x_train) / batch_size, \n",
        "                  epochs=epochs,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  callbacks=[set_lr, es],\n",
        "                  verbose=1)\n",
        "\n",
        "# Evaluate over test\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "500/500 [==============================] - 101s 202ms/step - loss: 1.7267 - accuracy: 0.4081 - val_loss: 1.6746 - val_accuracy: 0.4370\n",
            "Epoch 2/75\n",
            "500/500 [==============================] - 102s 203ms/step - loss: 1.5461 - accuracy: 0.4769 - val_loss: 1.6864 - val_accuracy: 0.4472\n",
            "Epoch 3/75\n",
            "500/500 [==============================] - 96s 192ms/step - loss: 1.4268 - accuracy: 0.5185 - val_loss: 2.0167 - val_accuracy: 0.4167\n",
            "Epoch 4/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 1.3223 - accuracy: 0.5599 - val_loss: 1.2717 - val_accuracy: 0.5855\n",
            "Epoch 5/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 1.2348 - accuracy: 0.5945 - val_loss: 1.4299 - val_accuracy: 0.5353\n",
            "Epoch 6/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 1.1665 - accuracy: 0.6202 - val_loss: 1.1997 - val_accuracy: 0.6112\n",
            "Epoch 7/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 1.1083 - accuracy: 0.6426 - val_loss: 1.2665 - val_accuracy: 0.6084\n",
            "Epoch 8/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 1.0648 - accuracy: 0.6558 - val_loss: 0.9770 - val_accuracy: 0.6882\n",
            "Epoch 9/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 1.0195 - accuracy: 0.6747 - val_loss: 1.1799 - val_accuracy: 0.6422\n",
            "Epoch 10/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 0.9838 - accuracy: 0.6857 - val_loss: 1.0895 - val_accuracy: 0.6636\n",
            "Epoch 11/75\n",
            "500/500 [==============================] - 102s 203ms/step - loss: 0.9553 - accuracy: 0.6978 - val_loss: 1.1404 - val_accuracy: 0.6512\n",
            "Epoch 12/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.9148 - accuracy: 0.7128 - val_loss: 0.8607 - val_accuracy: 0.7315\n",
            "Epoch 13/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.8926 - accuracy: 0.7207 - val_loss: 0.9256 - val_accuracy: 0.7054\n",
            "Epoch 14/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.8642 - accuracy: 0.7305 - val_loss: 1.0623 - val_accuracy: 0.6676\n",
            "Epoch 15/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.8361 - accuracy: 0.7363 - val_loss: 0.9540 - val_accuracy: 0.7200\n",
            "Epoch 16/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.8150 - accuracy: 0.7464 - val_loss: 1.1553 - val_accuracy: 0.6676\n",
            "Epoch 17/75\n",
            "500/500 [==============================] - 96s 192ms/step - loss: 0.8010 - accuracy: 0.7521 - val_loss: 0.9982 - val_accuracy: 0.7057\n",
            "Epoch 18/75\n",
            "500/500 [==============================] - 96s 192ms/step - loss: 0.7780 - accuracy: 0.7607 - val_loss: 1.1692 - val_accuracy: 0.6678\n",
            "Epoch 19/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.7613 - accuracy: 0.7630 - val_loss: 0.8389 - val_accuracy: 0.7524\n",
            "Epoch 20/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.7425 - accuracy: 0.7730 - val_loss: 0.8944 - val_accuracy: 0.7386\n",
            "Epoch 21/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.7324 - accuracy: 0.7768 - val_loss: 0.7042 - val_accuracy: 0.7891\n",
            "Epoch 22/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 0.7118 - accuracy: 0.7825 - val_loss: 0.8714 - val_accuracy: 0.7469\n",
            "Epoch 23/75\n",
            "500/500 [==============================] - 95s 191ms/step - loss: 0.6934 - accuracy: 0.7885 - val_loss: 0.8943 - val_accuracy: 0.7345\n",
            "Epoch 24/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 0.6849 - accuracy: 0.7903 - val_loss: 0.6921 - val_accuracy: 0.7956\n",
            "Epoch 25/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.6698 - accuracy: 0.7958 - val_loss: 0.7682 - val_accuracy: 0.7759\n",
            "Epoch 26/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 0.5796 - accuracy: 0.8275 - val_loss: 0.5751 - val_accuracy: 0.8336\n",
            "Epoch 27/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 0.5563 - accuracy: 0.8358 - val_loss: 0.5666 - val_accuracy: 0.8366\n",
            "Epoch 28/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 0.5511 - accuracy: 0.8369 - val_loss: 0.6010 - val_accuracy: 0.8275\n",
            "Epoch 29/75\n",
            "500/500 [==============================] - 102s 203ms/step - loss: 0.5393 - accuracy: 0.8406 - val_loss: 0.5559 - val_accuracy: 0.8397\n",
            "Epoch 30/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.5410 - accuracy: 0.8417 - val_loss: 0.5572 - val_accuracy: 0.8409\n",
            "Epoch 31/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 0.5334 - accuracy: 0.8433 - val_loss: 0.5877 - val_accuracy: 0.8356\n",
            "Epoch 32/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 0.5249 - accuracy: 0.8456 - val_loss: 0.5596 - val_accuracy: 0.8415\n",
            "Epoch 33/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 0.5244 - accuracy: 0.8451 - val_loss: 0.5274 - val_accuracy: 0.8510\n",
            "Epoch 34/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.5196 - accuracy: 0.8482 - val_loss: 0.5444 - val_accuracy: 0.8464\n",
            "Epoch 35/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.5151 - accuracy: 0.8490 - val_loss: 0.5623 - val_accuracy: 0.8405\n",
            "Epoch 36/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.5202 - accuracy: 0.8475 - val_loss: 0.5404 - val_accuracy: 0.8456\n",
            "Epoch 37/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 0.5072 - accuracy: 0.8524 - val_loss: 0.5384 - val_accuracy: 0.8464\n",
            "Epoch 38/75\n",
            "500/500 [==============================] - 102s 203ms/step - loss: 0.5097 - accuracy: 0.8510 - val_loss: 0.5361 - val_accuracy: 0.8477\n",
            "Epoch 39/75\n",
            "500/500 [==============================] - 102s 203ms/step - loss: 0.5107 - accuracy: 0.8506 - val_loss: 0.5498 - val_accuracy: 0.8448\n",
            "Epoch 40/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.5032 - accuracy: 0.8541 - val_loss: 0.5151 - val_accuracy: 0.8559\n",
            "Epoch 41/75\n",
            "500/500 [==============================] - 102s 203ms/step - loss: 0.5029 - accuracy: 0.8520 - val_loss: 0.5405 - val_accuracy: 0.8454\n",
            "Epoch 42/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.4991 - accuracy: 0.8523 - val_loss: 0.5798 - val_accuracy: 0.8364\n",
            "Epoch 43/75\n",
            "500/500 [==============================] - 102s 203ms/step - loss: 0.5005 - accuracy: 0.8533 - val_loss: 0.5459 - val_accuracy: 0.8457\n",
            "Epoch 44/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.4920 - accuracy: 0.8572 - val_loss: 0.5564 - val_accuracy: 0.8405\n",
            "Epoch 45/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.4954 - accuracy: 0.8556 - val_loss: 0.5356 - val_accuracy: 0.8483\n",
            "Epoch 46/75\n",
            "500/500 [==============================] - 102s 203ms/step - loss: 0.4909 - accuracy: 0.8563 - val_loss: 0.5357 - val_accuracy: 0.8483\n",
            "Epoch 47/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.4851 - accuracy: 0.8594 - val_loss: 0.5557 - val_accuracy: 0.8414\n",
            "Epoch 48/75\n",
            "500/500 [==============================] - 97s 193ms/step - loss: 0.4870 - accuracy: 0.8570 - val_loss: 0.5293 - val_accuracy: 0.8513\n",
            "Epoch 49/75\n",
            "500/500 [==============================] - 97s 194ms/step - loss: 0.4849 - accuracy: 0.8583 - val_loss: 0.5357 - val_accuracy: 0.8467\n",
            "Epoch 50/75\n",
            "500/500 [==============================] - 96s 192ms/step - loss: 0.4747 - accuracy: 0.8618 - val_loss: 0.5349 - val_accuracy: 0.8484\n",
            "Epoch 51/75\n",
            "500/500 [==============================] - 96s 191ms/step - loss: 0.4701 - accuracy: 0.8627 - val_loss: 0.5246 - val_accuracy: 0.8517\n",
            "Epoch 52/75\n",
            "500/500 [==============================] - 96s 191ms/step - loss: 0.4668 - accuracy: 0.8652 - val_loss: 0.5148 - val_accuracy: 0.8538\n",
            "Epoch 53/75\n",
            "500/500 [==============================] - 96s 191ms/step - loss: 0.4641 - accuracy: 0.8646 - val_loss: 0.5209 - val_accuracy: 0.8528\n",
            "Epoch 54/75\n",
            "500/500 [==============================] - 96s 192ms/step - loss: 0.4661 - accuracy: 0.8647 - val_loss: 0.5205 - val_accuracy: 0.8527\n",
            "Epoch 55/75\n",
            "500/500 [==============================] - 96s 192ms/step - loss: 0.4666 - accuracy: 0.8660 - val_loss: 0.5199 - val_accuracy: 0.8520\n",
            "Epoch 56/75\n",
            "500/500 [==============================] - 96s 192ms/step - loss: 0.4674 - accuracy: 0.8639 - val_loss: 0.5236 - val_accuracy: 0.8518\n",
            "Test loss: 0.5235641002655029\n",
            "Test accuracy: 0.8518000245094299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_oBDiZbbO0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ae026ca-9473-48bf-d29c-b70d355a41c4"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4uLWmxCbaq9"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlYhPH9bcz9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "0fa3c547-799e-4cad-b891-6487a5b16542"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}