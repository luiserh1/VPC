{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WideResnet_K4_NoPreTrained.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORvwib-YSR-p"
      },
      "source": [
        "CIFAR10 - WideResnet solution. Adaptación de https://www.kaggle.com/zjaume/resnet-cifar10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YRXPjE-Sf1a"
      },
      "source": [
        "Install Keras just in case..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhsFJNHpSSKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0662b070-e35a-4ff8-ecd4-81e8d02c664a"
      },
      "source": [
        "!pip3 install keras\n",
        "!pip3 install keras_applications"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n",
            "Collecting keras_applications\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.5.2)\n",
            "Installing collected packages: keras-applications\n",
            "Successfully installed keras-applications-1.0.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGX8RGwHSSTr"
      },
      "source": [
        "Imports..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8qeBuPiSSdc"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "\n",
        "import warnings\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Input, Conv2D, Add, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization as  BN\n",
        "from keras.layers.merge import add\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.engine.topology import get_source_inputs\n",
        "import keras.backend as K\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras import utils\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler as LRS\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M9uBGifSSqd"
      },
      "source": [
        "Define batch size, number of epochs and number of classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaWFWm8mSTBj"
      },
      "source": [
        "batch_size = 100\n",
        "num_classes = 10\n",
        "epochs = 75"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuM-ZML22Cn9",
        "outputId": "562eab67-32f1-47b0-f798-421e9ba897d2"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0CgF6jTejyx"
      },
      "source": [
        "## Data Augmentation with an ImageGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.3,\n",
        "    rotation_range=45,\n",
        "    vertical_flip=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdaMLtdhtd5j"
      },
      "source": [
        "Movidas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap_0BFfhRKEC"
      },
      "source": [
        "def bn_act(x, activation='relu'):\n",
        "    l = BN()(x)\n",
        "    if activation=='prelu':\n",
        "        l = PReLU()(l)\n",
        "    else:\n",
        "        l = Activation('relu')(l)\n",
        "    return l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwkmg_n-Rssm"
      },
      "source": [
        "def res_block(convs, identity=True, k=1):\n",
        "    def inner(x):\n",
        "        if not identity:\n",
        "            strides = (2,2)\n",
        "        else:\n",
        "            strides = (1,1)\n",
        "            \n",
        "        act = bn_act(x)\n",
        "        l = Conv2D(convs*k, 3, strides=strides, padding='same', kernel_initializer='he_normal')(act)\n",
        "        \n",
        "        l = bn_act(l)\n",
        "        l = Dropout(0.5)(l)\n",
        "        l = Conv2D(convs*k, 3, strides=(1,1), padding='same', kernel_initializer='he_normal')(l)\n",
        "        \n",
        "        if not identity or x.shape[3]!=convs*k:\n",
        "            shortcut = Conv2D(convs*k, 1, strides=strides, padding='same', kernel_initializer='he_normal')(act)\n",
        "            l = Add()([l,shortcut])\n",
        "        else:\n",
        "            l = Add()([l,x])\n",
        "        return l\n",
        "    return inner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt9-YGpZRtoj"
      },
      "source": [
        "def wide_resnet(input_shape, k=8):\n",
        "    inpt = Input(shape = input_shape)\n",
        "\n",
        "    # stage 1\n",
        "    x = Conv2D(16, 3, strides=(1,1), padding='same', kernel_initializer='he_normal')(inpt)\n",
        "    #x = bn_act(x)\n",
        "    #x = MaxPooling2D(pool_size=(3,3),strides=2)(x)\n",
        "    \n",
        "    n=28 # depth or total number of layers\n",
        "    N = (n-4)//6\n",
        "    # stage 2\n",
        "    for i in range(N):\n",
        "        x = res_block(16,k=k)(x)\n",
        "\n",
        "    # stage 3\n",
        "    x = res_block(32,False,k=k)(x)\n",
        "    for i in range(1,N):\n",
        "        x = res_block(32,k=k)(x)\n",
        "\n",
        "    # stage 4\n",
        "    x = res_block(64,False,k=k)(x)\n",
        "    for i in range(1,N):\n",
        "        x = res_block(64,k=k)(x)\n",
        "    \n",
        "    x = bn_act(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outpt = Dense(num_classes, activation=\"softmax\")(x)\n",
        "    model = Model(inpt,outpt)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF5v2bpcwZCy",
        "outputId": "a5fb3ae6-257c-4655-a962-d58bbbcb92cf"
      },
      "source": [
        "model = wide_resnet(x_train.shape[1:], k=4)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   448         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 64)   9280        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 64)   256         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 32, 32, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 64)   36928       dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 64)   1088        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 64)   0           conv2d_4[0][0]                   \n",
            "                                                                 conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 64)   256         add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 64)   36928       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 32, 32, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 64)   36928       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 64)   0           conv2d_7[0][0]                   \n",
            "                                                                 add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 64)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 32, 32, 64)   0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 64)   36928       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 64)   0           conv2d_9[0][0]                   \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 64)   36928       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 64)   256         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 32, 32, 64)   0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 64)   36928       dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 64)   0           conv2d_11[0][0]                  \n",
            "                                                                 add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 64)   256         add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 128)  73856       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 128)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 16, 16, 128)  0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 128)  147584      dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 128)  8320        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 128)  0           conv2d_13[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 128)  512         add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 128)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 128)  147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 16, 16, 128)  0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 128)  147584      dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 128)  0           conv2d_16[0][0]                  \n",
            "                                                                 add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 128)  512         add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 128)  147584      activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 128)  512         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 128)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 16, 16, 128)  0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 128)  147584      dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 128)  0           conv2d_18[0][0]                  \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 128)  512         add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 128)  0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 128)  147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 16, 16, 128)  0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 128)  147584      dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 16, 16, 128)  0           conv2d_20[0][0]                  \n",
            "                                                                 add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 8, 8, 256)    295168      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 256)    1024        conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 256)    0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 8, 8, 256)    0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 8, 8, 256)    590080      dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 8, 8, 256)    33024       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 256)    0           conv2d_22[0][0]                  \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 256)    1024        add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 256)    0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 8, 8, 256)    590080      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 8, 8, 256)    1024        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 8, 8, 256)    0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 8, 8, 256)    0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 256)    590080      dropout_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 256)    0           conv2d_25[0][0]                  \n",
            "                                                                 add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 8, 8, 256)    1024        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 8, 8, 256)    0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 256)    590080      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 8, 8, 256)    1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 8, 8, 256)    0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_10 (Dropout)            (None, 8, 8, 256)    0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 256)    590080      dropout_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 256)    0           conv2d_27[0][0]                  \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 8, 8, 256)    1024        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 256)    0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 256)    590080      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 8, 8, 256)    1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 8, 256)    0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_11 (Dropout)            (None, 8, 8, 256)    0           activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 256)    590080      dropout_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 256)    0           conv2d_29[0][0]                  \n",
            "                                                                 add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 8, 8, 256)    1024        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 8, 8, 256)    0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 256)          0           activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           2570        global_average_pooling2d[0][0]   \n",
            "==================================================================================================\n",
            "Total params: 5,860,298\n",
            "Trainable params: 5,853,098\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkDjl8exTTDZ"
      },
      "source": [
        "Define an optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTRuAT1FTTOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5eb8ec2-d6dd-4371-c2d3-0604ceba5daa"
      },
      "source": [
        "opt = SGD(lr=0.1, decay=1e-6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmhjZqVhfV18"
      },
      "source": [
        "DEFINE A LEARNING RATE SCHEDULER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjGe1KAwfV7F"
      },
      "source": [
        "def scheduler(epoch):\n",
        "    if epoch < 25:\n",
        "        return .1\n",
        "    elif epoch < 50:\n",
        "        return 0.01\n",
        "    else:\n",
        "        return 0.001\n",
        "\n",
        "# Callbacks\n",
        "set_lr = LRS(scheduler)\n",
        "es = keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHhBHWFjTTYy"
      },
      "source": [
        "Compile the model, define loss and link the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W8KCPtcTTii"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBOKdV6MTTtA"
      },
      "source": [
        "Finally, train the model and evaluate over the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLPsSdVDTT37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13e0550d-c073-48d4-d7ee-477c5465519f"
      },
      "source": [
        "history=model.fit(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                  steps_per_epoch=len(x_train) / batch_size, \n",
        "                  epochs=epochs,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  callbacks=[set_lr, es],\n",
        "                  verbose=1)\n",
        "\n",
        "# Evaluate over test\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "500/500 [==============================] - 128s 155ms/step - loss: 2.0324 - accuracy: 0.2346 - val_loss: 2.4537 - val_accuracy: 0.2751\n",
            "Epoch 2/75\n",
            "500/500 [==============================] - 76s 151ms/step - loss: 1.7129 - accuracy: 0.3677 - val_loss: 2.0598 - val_accuracy: 0.3714\n",
            "Epoch 3/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 1.5899 - accuracy: 0.4163 - val_loss: 2.0856 - val_accuracy: 0.3812\n",
            "Epoch 4/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 1.4797 - accuracy: 0.4633 - val_loss: 1.8285 - val_accuracy: 0.4447\n",
            "Epoch 5/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 1.3950 - accuracy: 0.4931 - val_loss: 1.5027 - val_accuracy: 0.4938\n",
            "Epoch 6/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 1.3256 - accuracy: 0.5235 - val_loss: 1.6666 - val_accuracy: 0.4749\n",
            "Epoch 7/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 1.2513 - accuracy: 0.5523 - val_loss: 1.4724 - val_accuracy: 0.5154\n",
            "Epoch 8/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 1.2071 - accuracy: 0.5690 - val_loss: 1.6721 - val_accuracy: 0.5296\n",
            "Epoch 9/75\n",
            "500/500 [==============================] - 76s 153ms/step - loss: 1.1561 - accuracy: 0.5859 - val_loss: 1.3868 - val_accuracy: 0.5712\n",
            "Epoch 10/75\n",
            "500/500 [==============================] - 76s 153ms/step - loss: 1.1270 - accuracy: 0.5965 - val_loss: 1.1216 - val_accuracy: 0.6217\n",
            "Epoch 11/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 1.0896 - accuracy: 0.6118 - val_loss: 1.0790 - val_accuracy: 0.6434\n",
            "Epoch 12/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 1.0521 - accuracy: 0.6300 - val_loss: 1.2585 - val_accuracy: 0.5950\n",
            "Epoch 13/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 1.0265 - accuracy: 0.6350 - val_loss: 1.1387 - val_accuracy: 0.6280\n",
            "Epoch 14/75\n",
            "500/500 [==============================] - 77s 153ms/step - loss: 0.9935 - accuracy: 0.6481 - val_loss: 1.1365 - val_accuracy: 0.6192\n",
            "Epoch 15/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.9660 - accuracy: 0.6577 - val_loss: 1.1884 - val_accuracy: 0.6166\n",
            "Epoch 16/75\n",
            "500/500 [==============================] - 77s 153ms/step - loss: 0.9423 - accuracy: 0.6685 - val_loss: 0.9548 - val_accuracy: 0.6861\n",
            "Epoch 17/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.9153 - accuracy: 0.6762 - val_loss: 0.9198 - val_accuracy: 0.6985\n",
            "Epoch 18/75\n",
            "500/500 [==============================] - 77s 153ms/step - loss: 0.9045 - accuracy: 0.6838 - val_loss: 1.0137 - val_accuracy: 0.6770\n",
            "Epoch 19/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.8805 - accuracy: 0.6938 - val_loss: 0.8700 - val_accuracy: 0.7120\n",
            "Epoch 20/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.8516 - accuracy: 0.7004 - val_loss: 0.8709 - val_accuracy: 0.7219\n",
            "Epoch 21/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.8350 - accuracy: 0.7041 - val_loss: 0.9236 - val_accuracy: 0.7019\n",
            "Epoch 22/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.8114 - accuracy: 0.7133 - val_loss: 0.9159 - val_accuracy: 0.7025\n",
            "Epoch 23/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.8020 - accuracy: 0.7199 - val_loss: 1.1028 - val_accuracy: 0.6676\n",
            "Epoch 24/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.7844 - accuracy: 0.7235 - val_loss: 1.4749 - val_accuracy: 0.6011\n",
            "Epoch 25/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.7656 - accuracy: 0.7317 - val_loss: 0.9604 - val_accuracy: 0.7119\n",
            "Epoch 26/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.7226 - accuracy: 0.7472 - val_loss: 0.7158 - val_accuracy: 0.7685\n",
            "Epoch 27/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.7027 - accuracy: 0.7551 - val_loss: 0.7510 - val_accuracy: 0.7560\n",
            "Epoch 28/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.6878 - accuracy: 0.7602 - val_loss: 0.7088 - val_accuracy: 0.7714\n",
            "Epoch 29/75\n",
            "500/500 [==============================] - 76s 153ms/step - loss: 0.6920 - accuracy: 0.7558 - val_loss: 0.7466 - val_accuracy: 0.7606\n",
            "Epoch 30/75\n",
            "500/500 [==============================] - 76s 151ms/step - loss: 0.6891 - accuracy: 0.7570 - val_loss: 0.7121 - val_accuracy: 0.7708\n",
            "Epoch 31/75\n",
            "500/500 [==============================] - 76s 153ms/step - loss: 0.6779 - accuracy: 0.7626 - val_loss: 0.7035 - val_accuracy: 0.7757\n",
            "Epoch 32/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.6853 - accuracy: 0.7577 - val_loss: 0.6834 - val_accuracy: 0.7837\n",
            "Epoch 33/75\n",
            "500/500 [==============================] - 76s 153ms/step - loss: 0.6907 - accuracy: 0.7587 - val_loss: 0.7196 - val_accuracy: 0.7735\n",
            "Epoch 34/75\n",
            "500/500 [==============================] - 76s 151ms/step - loss: 0.6760 - accuracy: 0.7609 - val_loss: 0.6780 - val_accuracy: 0.7831\n",
            "Epoch 35/75\n",
            "500/500 [==============================] - 76s 152ms/step - loss: 0.6757 - accuracy: 0.7644 - val_loss: 0.7409 - val_accuracy: 0.7691\n",
            "Epoch 36/75\n",
            "500/500 [==============================] - 76s 151ms/step - loss: 0.6728 - accuracy: 0.7629 - val_loss: 0.7044 - val_accuracy: 0.7780\n",
            "Epoch 37/75\n",
            "500/500 [==============================] - 76s 151ms/step - loss: 0.6764 - accuracy: 0.7647 - val_loss: 0.7066 - val_accuracy: 0.7776\n",
            "Test loss: 0.7066270709037781\n",
            "Test accuracy: 0.7775999903678894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_oBDiZbbO0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1493e12-86a4-4ea9-ad82-54ad79b3bda2"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4uLWmxCbaq9"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlYhPH9bcz9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "be54df04-4e99-44bd-b81d-bf47b84c36a3"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}