{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WideResnet_K8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORvwib-YSR-p"
      },
      "source": [
        "CIFAR10 - WideResnet solution. AdaptaciÃ³n de https://github.com/keras-team/keras-contrib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YRXPjE-Sf1a"
      },
      "source": [
        "Install Keras just in case..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhsFJNHpSSKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20cf3fc4-0439-4c6a-af3c-7235bf42984b"
      },
      "source": [
        "!pip3 install keras\n",
        "!pip3 install keras_applications"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n",
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGX8RGwHSSTr"
      },
      "source": [
        "Imports..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8qeBuPiSSdc"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "\n",
        "import warnings\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Input, Conv2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.merge import add\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.engine.topology import get_source_inputs\n",
        "import keras.backend as K\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras import utils\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler as LRS\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "from keras.applications import \n",
        "\n",
        "import keras"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M9uBGifSSqd"
      },
      "source": [
        "Define batch size, number of epochs and number of classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaWFWm8mSTBj"
      },
      "source": [
        "batch_size = 100\n",
        "num_classes = 10\n",
        "epochs = 75"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuM-ZML22Cn9",
        "outputId": "fe4650c6-1890-45f4-ba66-3b663196cd02"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0CgF6jTejyx"
      },
      "source": [
        "## Data Augmentation with an ImageGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.3,\n",
        "    rotation_range=45,\n",
        "    vertical_flip=False)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdaMLtdhtd5j"
      },
      "source": [
        "Movidas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1suOwiptfvl"
      },
      "source": [
        "TH_WEIGHTS_PATH = ('https://github.com/titu1994/Wide-Residual-Networks/'\n",
        "                   'releases/download/v1.2/wrn_28_8_th_kernels_th_dim_ordering.h5')\n",
        "TF_WEIGHTS_PATH = ('https://github.com/titu1994/Wide-Residual-Networks/'\n",
        "                   'releases/download/v1.2/wrn_28_8_tf_kernels_tf_dim_ordering.h5')\n",
        "TH_WEIGHTS_PATH_NO_TOP = ('https://github.com/titu1994/Wide-Residual-Networks/releases/'\n",
        "                          'download/v1.2/wrn_28_8_th_kernels_th_dim_ordering_no_top.h5')\n",
        "TF_WEIGHTS_PATH_NO_TOP = ('https://github.com/titu1994/Wide-Residual-Networks/releases/'\n",
        "                          'download/v1.2/wrn_28_8_tf_kernels_tf_dim_ordering_no_top.h5')"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTpFyrq2tpki"
      },
      "source": [
        "def WideResidualNetwork(depth=28, width=8, dropout_rate=0.0,\n",
        "                        include_top=True, weights='cifar10',\n",
        "                        input_tensor=None, input_shape=None,\n",
        "                        classes=10, activation='softmax'):\n",
        "    \"\"\"Instantiate the Wide Residual Network architecture,\n",
        "        optionally loading weights pre-trained\n",
        "        on CIFAR-10. Note that when using TensorFlow,\n",
        "        for best performance you should set\n",
        "        `image_dim_ordering=\"tf\"` in your Keras config\n",
        "        at ~/.keras/keras.json.\n",
        "        # Arguments\n",
        "            depth: number or layers in the DenseNet\n",
        "            width: multiplier to the ResNet width (number of filters)\n",
        "            dropout_rate: dropout rate\n",
        "            include_top: whether to include the fully-connected\n",
        "                layer at the top of the network.\n",
        "            weights: one of `None` (random initialization) or\n",
        "                \"cifar10\" (pre-training on CIFAR-10)..\n",
        "            input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "                to use as image input for the model.\n",
        "            input_shape: optional shape tuple, only to be specified\n",
        "                if `include_top` is False (otherwise the input shape\n",
        "                has to be `(32, 32, 3)` (with `tf` dim ordering)\n",
        "                or `(3, 32, 32)` (with `th` dim ordering).\n",
        "                It should have exactly 3 inputs channels,\n",
        "                and width and height should be no smaller than 8.\n",
        "                E.g. `(200, 200, 3)` would be one valid value.\n",
        "            classes: optional number of classes to classify images\n",
        "                into, only to be specified if `include_top` is True, and\n",
        "                if no `weights` argument is specified.\n",
        "        # Returns\n",
        "            A Keras model instance.\n",
        "        \"\"\"\n",
        "\n",
        "    if weights not in {'cifar10', None}:\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or `cifar10` '\n",
        "                         '(pre-training on CIFAR-10).')\n",
        "\n",
        "    if weights == 'cifar10' and include_top and classes != 10:\n",
        "        raise ValueError('If using `weights` as CIFAR 10 with `include_top`'\n",
        "                         ' as true, `classes` should be 10')\n",
        "\n",
        "    if (depth - 4) % 6 != 0:\n",
        "        raise ValueError('Depth of the network must be such that (depth - 4)'\n",
        "                         'should be divisible by 6.')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=32,\n",
        "                                      min_size=8,\n",
        "                                      data_format=K.image_data_format(),\n",
        "                                      require_flatten=include_top)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    x = __create_wide_residual_network(classes, img_input, include_top, depth, width,\n",
        "                                       dropout_rate, activation)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = Model(inputs, x, name='wide-resnet')\n",
        "\n",
        "    # load weights\n",
        "    if weights == 'cifar10':\n",
        "        if (depth == 28) and (width == 8) and (dropout_rate == 0.0):\n",
        "            # Default parameters match. Weights for this model exist:\n",
        "\n",
        "            if K.image_data_format() == 'th':\n",
        "                if include_top:\n",
        "                    h5_file = 'wide_resnet_28_8_th_dim_ordering_th_kernels.h5'\n",
        "                    weights_path = get_file(h5_file,\n",
        "                                            TH_WEIGHTS_PATH,\n",
        "                                            cache_subdir='models')\n",
        "                else:\n",
        "                    h5_file = 'wide_resnet_28_8_th_dim_ordering_th_kernels_no_top.h5'\n",
        "                    weights_path = get_file(h5_file,\n",
        "                                            TH_WEIGHTS_PATH_NO_TOP,\n",
        "                                            cache_subdir='models')\n",
        "\n",
        "                model.load_weights(weights_path)\n",
        "\n",
        "                if K.backend() == 'tensorflow':\n",
        "                    warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                                  'are using the Theano '\n",
        "                                  'image dimension ordering convention '\n",
        "                                  '(`image_dim_ordering=\"th\"`). '\n",
        "                                  'For best performance, set '\n",
        "                                  '`image_dim_ordering=\"tf\"` in '\n",
        "                                  'your Keras config '\n",
        "                                  'at ~/.keras/keras.json.')\n",
        "                    convert_all_kernels_in_model(model)\n",
        "            else:\n",
        "                if include_top:\n",
        "                    h5_file = 'wide_resnet_28_8_tf_dim_ordering_tf_kernels.h5'\n",
        "                    weights_path = get_file(h5_file,\n",
        "                                            TF_WEIGHTS_PATH,\n",
        "                                            cache_subdir='models')\n",
        "                else:\n",
        "                    h5_file = 'wide_resnet_28_8_tf_dim_ordering_tf_kernels_no_top.h5'\n",
        "                    weights_path = get_file(h5_file,\n",
        "                                            TF_WEIGHTS_PATH_NO_TOP,\n",
        "                                            cache_subdir='models')\n",
        "\n",
        "                model.load_weights(weights_path)\n",
        "\n",
        "                if K.backend() == 'theano':\n",
        "                    convert_all_kernels_in_model(model)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XocORwFNuqBW"
      },
      "source": [
        "def __conv1_block(input):\n",
        "    x = Conv2D(16, (3, 3), padding='same')(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gWRJewyut5o"
      },
      "source": [
        "def __conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "    # Check if input number of filters is same as 16 * k, else create\n",
        "    # convolution2d for this input\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        if init.shape[1] != 16 * k:\n",
        "            init = Conv2D(16 * k, (1, 1), activation='linear', padding='same')(init)\n",
        "    else:\n",
        "        if init.shape[-1] != 16 * k:\n",
        "            init = Conv2D(16 * k, (1, 1), activation='linear', padding='same')(init)\n",
        "\n",
        "    x = Conv2D(16 * k, (3, 3), padding='same')(input)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    if dropout > 0.0:\n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    x = Conv2D(16 * k, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    m = add([init, x])\n",
        "    return m"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFy6tdc0STtb"
      },
      "source": [
        "def __conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "    # Check if input number of filters is same as 32 * k, else\n",
        "    # create convolution2d for this input\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        if init.shape[1] != 32 * k:\n",
        "            init = Conv2D(32 * k, (1, 1), activation='linear', padding='same')(init)\n",
        "    else:\n",
        "        if init.shape[-1] != 32 * k:\n",
        "            init = Conv2D(32 * k, (1, 1), activation='linear', padding='same')(init)\n",
        "\n",
        "    x = Conv2D(32 * k, (3, 3), padding='same')(input)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    if dropout > 0.0:\n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    x = Conv2D(32 * k, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    m = add([init, x])\n",
        "    return m"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4M-TpcKvhiS"
      },
      "source": [
        "def ___conv4_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == 'th' else -1\n",
        "\n",
        "    # Check if input number of filters is same as 64 * k, else\n",
        "    # create convolution2d for this input\n",
        "    if K.image_data_format() == 'th':\n",
        "        if init.shape[1] != 64 * k:\n",
        "            init = Conv2D(64 * k, (1, 1), activation='linear', padding='same')(init)\n",
        "    else:\n",
        "        if init.shape[-1] != 64 * k:\n",
        "            init = Conv2D(64 * k, (1, 1), activation='linear', padding='same')(init)\n",
        "\n",
        "    x = Conv2D(64 * k, (3, 3), padding='same')(input)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    if dropout > 0.0:\n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    x = Conv2D(64 * k, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    m = add([init, x])\n",
        "    return m"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUq-_yZ_vnBS"
      },
      "source": [
        "def __create_wide_residual_network(nb_classes, img_input, include_top, depth=28,\n",
        "                                   width=8, dropout=0.0, activation='softmax'):\n",
        "    ''' Creates a Wide Residual Network with specified parameters\n",
        "    Args:\n",
        "        nb_classes: Number of output classes\n",
        "        img_input: Input tensor or layer\n",
        "        include_top: Flag to include the last dense layer\n",
        "        depth: Depth of the network. Compute N = (n - 4) / 6.\n",
        "               For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "               For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "               For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "        width: Width of the network.\n",
        "        dropout: Adds dropout if value is greater than 0.0\n",
        "    Returns:a Keras Model\n",
        "    '''\n",
        "\n",
        "    N = (depth - 4) // 6\n",
        "\n",
        "    x = __conv1_block(img_input)\n",
        "    nb_conv = 4\n",
        "\n",
        "    for i in range(N):\n",
        "        x = __conv2_block(x, width, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    for i in range(N):\n",
        "        x = __conv3_block(x, width, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    for i in range(N):\n",
        "        x = ___conv4_block(x, width, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    if include_top:\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Dense(nb_classes, activation=activation)(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF5v2bpcwZCy",
        "outputId": "d8b066bd-effa-4a60-ca30-48ad6ad85a1d"
      },
      "source": [
        "model = WideResidualNetwork()\n",
        "model.summary()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"wide-resnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 32, 32, 16)   448         input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 32, 32, 16)   64          conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 32, 32, 16)   0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 32, 32, 128)  18560       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 32, 32, 128)  512         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 32, 32, 128)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 32, 32, 128)  147584      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 32, 32, 128)  512         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 32, 32, 128)  2176        activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 32, 32, 128)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 32, 32, 128)  0           conv2d_153[0][0]                 \n",
            "                                                                 activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 32, 32, 128)  147584      add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 32, 32, 128)  512         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 32, 32, 128)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 32, 32, 128)  147584      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 32, 32, 128)  512         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 32, 32, 128)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 32, 32, 128)  0           add_64[0][0]                     \n",
            "                                                                 activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 32, 32, 128)  147584      add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 32, 32, 128)  512         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 32, 32, 128)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 32, 32, 128)  147584      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 32, 32, 128)  512         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 32, 32, 128)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_66 (Add)                    (None, 32, 32, 128)  0           add_65[0][0]                     \n",
            "                                                                 activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 32, 32, 128)  147584      add_66[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 32, 32, 128)  512         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 32, 32, 128)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 32, 32, 128)  147584      activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 32, 32, 128)  512         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 32, 32, 128)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_67 (Add)                    (None, 32, 32, 128)  0           add_66[0][0]                     \n",
            "                                                                 activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 16, 16, 128)  0           add_67[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 16, 16, 256)  295168      max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 16, 16, 256)  1024        conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 16, 16, 256)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 16, 16, 256)  590080      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 16, 16, 256)  1024        conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 16, 16, 256)  33024       max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 16, 16, 256)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_68 (Add)                    (None, 16, 16, 256)  0           conv2d_162[0][0]                 \n",
            "                                                                 activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 16, 16, 256)  590080      add_68[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 16, 16, 256)  1024        conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 16, 16, 256)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 16, 16, 256)  590080      activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 16, 16, 256)  1024        conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 16, 16, 256)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_69 (Add)                    (None, 16, 16, 256)  0           add_68[0][0]                     \n",
            "                                                                 activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 16, 16, 256)  590080      add_69[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 16, 16, 256)  1024        conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 16, 16, 256)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 16, 16, 256)  590080      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 16, 16, 256)  1024        conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 16, 16, 256)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_70 (Add)                    (None, 16, 16, 256)  0           add_69[0][0]                     \n",
            "                                                                 activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 16, 16, 256)  590080      add_70[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 16, 16, 256)  1024        conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 16, 16, 256)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 16, 16, 256)  590080      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 16, 16, 256)  1024        conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 16, 16, 256)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_71 (Add)                    (None, 16, 16, 256)  0           add_70[0][0]                     \n",
            "                                                                 activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 8, 8, 256)    0           add_71[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 8, 8, 512)    1180160     max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 8, 8, 512)    2048        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 8, 8, 512)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 8, 8, 512)    2359808     activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 8, 8, 512)    2048        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 8, 8, 512)    131584      max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 8, 8, 512)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_72 (Add)                    (None, 8, 8, 512)    0           conv2d_171[0][0]                 \n",
            "                                                                 activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 8, 8, 512)    2359808     add_72[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 8, 8, 512)    2048        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 8, 8, 512)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 8, 8, 512)    2359808     activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 8, 8, 512)    2048        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 8, 8, 512)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_73 (Add)                    (None, 8, 8, 512)    0           add_72[0][0]                     \n",
            "                                                                 activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 8, 8, 512)    2359808     add_73[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 8, 8, 512)    2048        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 8, 8, 512)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 8, 8, 512)    2359808     activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 8, 8, 512)    2048        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 8, 8, 512)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_74 (Add)                    (None, 8, 8, 512)    0           add_73[0][0]                     \n",
            "                                                                 activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 8, 8, 512)    2359808     add_74[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 8, 8, 512)    2048        conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 8, 8, 512)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 8, 8, 512)    2359808     activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 8, 8, 512)    2048        conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 8, 8, 512)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_75 (Add)                    (None, 8, 8, 512)    0           add_74[0][0]                     \n",
            "                                                                 activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 512)          0           add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           5130        global_average_pooling2d_3[0][0] \n",
            "==================================================================================================\n",
            "Total params: 23,377,290\n",
            "Trainable params: 23,362,922\n",
            "Non-trainable params: 14,368\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkDjl8exTTDZ"
      },
      "source": [
        "Define an optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTRuAT1FTTOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e954de01-3baa-479d-800d-aee93dc18f72"
      },
      "source": [
        "opt = SGD(lr=0.1, decay=1e-6)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmhjZqVhfV18"
      },
      "source": [
        "DEFINE A LEARNING RATE SCHEDULER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjGe1KAwfV7F"
      },
      "source": [
        "def scheduler(epoch):\n",
        "    if epoch < 25:\n",
        "        return .1\n",
        "    elif epoch < 50:\n",
        "        return 0.01\n",
        "    else:\n",
        "        return 0.001\n",
        "\n",
        "# Callbacks\n",
        "set_lr = LRS(scheduler)\n",
        "es = keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHhBHWFjTTYy"
      },
      "source": [
        "Compile the model, define loss and link the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W8KCPtcTTii"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBOKdV6MTTtA"
      },
      "source": [
        "Finally, train the model and evaluate over the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLPsSdVDTT37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b36995-6ef3-4276-9920-2829a00f9441"
      },
      "source": [
        "history=model.fit(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                  steps_per_epoch=len(x_train) / batch_size, \n",
        "                  epochs=epochs,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  callbacks=[set_lr, es],\n",
        "                  verbose=1)\n",
        "\n",
        "# Evaluate over test\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "500/500 [==============================] - 185s 360ms/step - loss: 0.7918 - accuracy: 0.7613 - val_loss: 0.2463 - val_accuracy: 0.9196\n",
            "Epoch 2/75\n",
            "500/500 [==============================] - 176s 351ms/step - loss: 0.5052 - accuracy: 0.8255 - val_loss: 0.1775 - val_accuracy: 0.9413\n",
            "Epoch 3/75\n",
            "500/500 [==============================] - 176s 352ms/step - loss: 0.4767 - accuracy: 0.8380 - val_loss: 0.1652 - val_accuracy: 0.9476\n",
            "Epoch 4/75\n",
            "500/500 [==============================] - 176s 352ms/step - loss: 0.4645 - accuracy: 0.8405 - val_loss: 0.1464 - val_accuracy: 0.9498\n",
            "Epoch 5/75\n",
            "500/500 [==============================] - 175s 351ms/step - loss: 0.4374 - accuracy: 0.8482 - val_loss: 0.1394 - val_accuracy: 0.9554\n",
            "Epoch 6/75\n",
            "500/500 [==============================] - 176s 351ms/step - loss: 0.4292 - accuracy: 0.8507 - val_loss: 0.1274 - val_accuracy: 0.9602\n",
            "Epoch 7/75\n",
            "500/500 [==============================] - 176s 352ms/step - loss: 0.4286 - accuracy: 0.8523 - val_loss: 0.1107 - val_accuracy: 0.9632\n",
            "Epoch 8/75\n",
            "500/500 [==============================] - 175s 351ms/step - loss: 0.4167 - accuracy: 0.8571 - val_loss: 0.1352 - val_accuracy: 0.9561\n",
            "Epoch 9/75\n",
            "500/500 [==============================] - 175s 350ms/step - loss: 0.4117 - accuracy: 0.8594 - val_loss: 0.1250 - val_accuracy: 0.9585\n",
            "Epoch 10/75\n",
            "500/500 [==============================] - 175s 351ms/step - loss: 0.3975 - accuracy: 0.8621 - val_loss: 0.1487 - val_accuracy: 0.9522\n",
            "Epoch 11/75\n",
            "500/500 [==============================] - 175s 351ms/step - loss: 0.4028 - accuracy: 0.8603 - val_loss: 0.1107 - val_accuracy: 0.9658\n",
            "Epoch 12/75\n",
            "500/500 [==============================] - 176s 351ms/step - loss: 0.3819 - accuracy: 0.8660 - val_loss: 0.1485 - val_accuracy: 0.9512\n",
            "Epoch 13/75\n",
            "500/500 [==============================] - 175s 351ms/step - loss: 0.3831 - accuracy: 0.8691 - val_loss: 0.1234 - val_accuracy: 0.9592\n",
            "Epoch 14/75\n",
            "500/500 [==============================] - 175s 350ms/step - loss: 0.3824 - accuracy: 0.8683 - val_loss: 0.1291 - val_accuracy: 0.9579\n",
            "Epoch 15/75\n",
            "500/500 [==============================] - 175s 351ms/step - loss: 0.3729 - accuracy: 0.8706 - val_loss: 0.1294 - val_accuracy: 0.9576\n",
            "Epoch 16/75\n",
            "500/500 [==============================] - 175s 350ms/step - loss: 0.3732 - accuracy: 0.8728 - val_loss: 0.1372 - val_accuracy: 0.9536\n",
            "Epoch 17/75\n",
            "500/500 [==============================] - 174s 349ms/step - loss: 0.3744 - accuracy: 0.8698 - val_loss: 0.1320 - val_accuracy: 0.9553\n",
            "Epoch 18/75\n",
            "500/500 [==============================] - 175s 351ms/step - loss: 0.3574 - accuracy: 0.8731 - val_loss: 0.1457 - val_accuracy: 0.9515\n",
            "Epoch 19/75\n",
            "500/500 [==============================] - 176s 351ms/step - loss: 0.3599 - accuracy: 0.8743 - val_loss: 0.1025 - val_accuracy: 0.9667\n",
            "Epoch 20/75\n",
            "500/500 [==============================] - 176s 351ms/step - loss: 0.3612 - accuracy: 0.8767 - val_loss: 0.1232 - val_accuracy: 0.9594\n",
            "Epoch 21/75\n",
            "500/500 [==============================] - 175s 350ms/step - loss: 0.3499 - accuracy: 0.8785 - val_loss: 0.1521 - val_accuracy: 0.9513\n",
            "Epoch 22/75\n",
            "500/500 [==============================] - 176s 352ms/step - loss: 0.3560 - accuracy: 0.8760 - val_loss: 0.0990 - val_accuracy: 0.9697\n",
            "Epoch 23/75\n",
            "500/500 [==============================] - 176s 352ms/step - loss: 0.3454 - accuracy: 0.8813 - val_loss: 0.1070 - val_accuracy: 0.9654\n",
            "Epoch 24/75\n",
            "500/500 [==============================] - 176s 351ms/step - loss: 0.3469 - accuracy: 0.8782 - val_loss: 0.1122 - val_accuracy: 0.9634\n",
            "Epoch 25/75\n",
            "500/500 [==============================] - 176s 352ms/step - loss: 0.3578 - accuracy: 0.8767 - val_loss: 0.1162 - val_accuracy: 0.9605\n",
            "Epoch 26/75\n",
            "500/500 [==============================] - 176s 352ms/step - loss: 0.3372 - accuracy: 0.8817 - val_loss: 0.0974 - val_accuracy: 0.9689\n",
            "Epoch 27/75\n",
            "500/500 [==============================] - 176s 352ms/step - loss: 0.3193 - accuracy: 0.8877 - val_loss: 0.0954 - val_accuracy: 0.9698\n",
            "Epoch 28/75\n",
            "500/500 [==============================] - 175s 350ms/step - loss: 0.3259 - accuracy: 0.8894 - val_loss: 0.0972 - val_accuracy: 0.9678\n",
            "Epoch 29/75\n",
            "500/500 [==============================] - 176s 352ms/step - loss: 0.3286 - accuracy: 0.8858 - val_loss: 0.0962 - val_accuracy: 0.9695\n",
            "Epoch 30/75\n",
            "500/500 [==============================] - 176s 351ms/step - loss: 0.3186 - accuracy: 0.8902 - val_loss: 0.0945 - val_accuracy: 0.9694\n",
            "Epoch 31/75\n",
            "500/500 [==============================] - 176s 351ms/step - loss: 0.3227 - accuracy: 0.8877 - val_loss: 0.0977 - val_accuracy: 0.9673\n",
            "Epoch 32/75\n",
            "500/500 [==============================] - 176s 352ms/step - loss: 0.3223 - accuracy: 0.8901 - val_loss: 0.0911 - val_accuracy: 0.9706\n",
            "Epoch 33/75\n",
            "500/500 [==============================] - 176s 352ms/step - loss: 0.3188 - accuracy: 0.8885 - val_loss: 0.0919 - val_accuracy: 0.9700\n",
            "Epoch 34/75\n",
            "500/500 [==============================] - 176s 351ms/step - loss: 0.3174 - accuracy: 0.8893 - val_loss: 0.0960 - val_accuracy: 0.9690\n",
            "Epoch 35/75\n",
            "500/500 [==============================] - 175s 351ms/step - loss: 0.3171 - accuracy: 0.8910 - val_loss: 0.0963 - val_accuracy: 0.9699\n",
            "Test loss: 0.09629250317811966\n",
            "Test accuracy: 0.9699000120162964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_oBDiZbbO0G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8abff73-b873-4ef8-fe0a-1ed36f078d3e"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4uLWmxCbaq9"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlYhPH9bcz9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "470c1b3a-e022-4741-f128-18da1d7bf430"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}