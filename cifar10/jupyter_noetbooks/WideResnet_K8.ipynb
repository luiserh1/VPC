{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WideResnet_K8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORvwib-YSR-p"
      },
      "source": [
        "CIFAR10 - WideResnet solution. AdaptaciÃ³n de https://github.com/keras-team/keras-contrib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YRXPjE-Sf1a"
      },
      "source": [
        "Install Keras just in case..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhsFJNHpSSKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20cf3fc4-0439-4c6a-af3c-7235bf42984b"
      },
      "source": [
        "!pip3 install keras\n",
        "!pip3 install keras_applications"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (3.1.0)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.5.2)\n",
            "Requirement already satisfied: keras_applications in /usr/local/lib/python3.7/dist-packages (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras_applications) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras_applications) (1.19.5)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py->keras_applications) (1.5.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGX8RGwHSSTr"
      },
      "source": [
        "Imports..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8qeBuPiSSdc"
      },
      "source": [
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "\n",
        "import warnings\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D\n",
        "from keras.layers import Input, Conv2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.merge import add\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.engine.topology import get_source_inputs\n",
        "import keras.backend as K\n",
        "from keras_applications.imagenet_utils import _obtain_input_shape\n",
        "from keras import utils\n",
        "\n",
        "from keras.callbacks import LearningRateScheduler as LRS\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "import keras"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-M9uBGifSSqd"
      },
      "source": [
        "Define batch size, number of epochs and number of classes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaWFWm8mSTBj"
      },
      "source": [
        "batch_size = 100\n",
        "epochs = 75"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0CgF6jTejyx"
      },
      "source": [
        "## Data Augmentation with an ImageGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.3,\n",
        "    rotation_range=45,\n",
        "    vertical_flip=False)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdaMLtdhtd5j"
      },
      "source": [
        "Movidas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1suOwiptfvl"
      },
      "source": [
        "TH_WEIGHTS_PATH = ('https://github.com/titu1994/Wide-Residual-Networks/'\n",
        "                   'releases/download/v1.2/wrn_28_8_th_kernels_th_dim_ordering.h5')\n",
        "TF_WEIGHTS_PATH = ('https://github.com/titu1994/Wide-Residual-Networks/'\n",
        "                   'releases/download/v1.2/wrn_28_8_tf_kernels_tf_dim_ordering.h5')\n",
        "TH_WEIGHTS_PATH_NO_TOP = ('https://github.com/titu1994/Wide-Residual-Networks/releases/'\n",
        "                          'download/v1.2/wrn_28_8_th_kernels_th_dim_ordering_no_top.h5')\n",
        "TF_WEIGHTS_PATH_NO_TOP = ('https://github.com/titu1994/Wide-Residual-Networks/releases/'\n",
        "                          'download/v1.2/wrn_28_8_tf_kernels_tf_dim_ordering_no_top.h5')"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTpFyrq2tpki"
      },
      "source": [
        "def WideResidualNetwork(depth=28, width=8, dropout_rate=0.0,\n",
        "                        include_top=True, weights='cifar10',\n",
        "                        input_tensor=None, input_shape=None,\n",
        "                        classes=10, activation='softmax'):\n",
        "    \"\"\"Instantiate the Wide Residual Network architecture,\n",
        "        optionally loading weights pre-trained\n",
        "        on CIFAR-10. Note that when using TensorFlow,\n",
        "        for best performance you should set\n",
        "        `image_dim_ordering=\"tf\"` in your Keras config\n",
        "        at ~/.keras/keras.json.\n",
        "        # Arguments\n",
        "            depth: number or layers in the DenseNet\n",
        "            width: multiplier to the ResNet width (number of filters)\n",
        "            dropout_rate: dropout rate\n",
        "            include_top: whether to include the fully-connected\n",
        "                layer at the top of the network.\n",
        "            weights: one of `None` (random initialization) or\n",
        "                \"cifar10\" (pre-training on CIFAR-10)..\n",
        "            input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
        "                to use as image input for the model.\n",
        "            input_shape: optional shape tuple, only to be specified\n",
        "                if `include_top` is False (otherwise the input shape\n",
        "                has to be `(32, 32, 3)` (with `tf` dim ordering)\n",
        "                or `(3, 32, 32)` (with `th` dim ordering).\n",
        "                It should have exactly 3 inputs channels,\n",
        "                and width and height should be no smaller than 8.\n",
        "                E.g. `(200, 200, 3)` would be one valid value.\n",
        "            classes: optional number of classes to classify images\n",
        "                into, only to be specified if `include_top` is True, and\n",
        "                if no `weights` argument is specified.\n",
        "        # Returns\n",
        "            A Keras model instance.\n",
        "        \"\"\"\n",
        "\n",
        "    if weights not in {'cifar10', None}:\n",
        "        raise ValueError('The `weights` argument should be either '\n",
        "                         '`None` (random initialization) or `cifar10` '\n",
        "                         '(pre-training on CIFAR-10).')\n",
        "\n",
        "    if weights == 'cifar10' and include_top and classes != 10:\n",
        "        raise ValueError('If using `weights` as CIFAR 10 with `include_top`'\n",
        "                         ' as true, `classes` should be 10')\n",
        "\n",
        "    if (depth - 4) % 6 != 0:\n",
        "        raise ValueError('Depth of the network must be such that (depth - 4)'\n",
        "                         'should be divisible by 6.')\n",
        "\n",
        "    # Determine proper input shape\n",
        "    input_shape = _obtain_input_shape(input_shape,\n",
        "                                      default_size=32,\n",
        "                                      min_size=8,\n",
        "                                      data_format=K.image_data_format(),\n",
        "                                      require_flatten=include_top)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    x = __create_wide_residual_network(classes, img_input, include_top, depth, width,\n",
        "                                       dropout_rate, activation)\n",
        "\n",
        "    # Ensure that the model takes into account\n",
        "    # any potential predecessors of `input_tensor`.\n",
        "    if input_tensor is not None:\n",
        "        inputs = get_source_inputs(input_tensor)\n",
        "    else:\n",
        "        inputs = img_input\n",
        "    # Create model.\n",
        "    model = Model(inputs, x, name='wide-resnet')\n",
        "\n",
        "    # load weights\n",
        "    if weights == 'cifar10':\n",
        "        if (depth == 28) and (width == 8) and (dropout_rate == 0.0):\n",
        "            # Default parameters match. Weights for this model exist:\n",
        "\n",
        "            if K.image_data_format() == 'th':\n",
        "                if include_top:\n",
        "                    h5_file = 'wide_resnet_28_8_th_dim_ordering_th_kernels.h5'\n",
        "                    weights_path = get_file(h5_file,\n",
        "                                            TH_WEIGHTS_PATH,\n",
        "                                            cache_subdir='models')\n",
        "                else:\n",
        "                    h5_file = 'wide_resnet_28_8_th_dim_ordering_th_kernels_no_top.h5'\n",
        "                    weights_path = get_file(h5_file,\n",
        "                                            TH_WEIGHTS_PATH_NO_TOP,\n",
        "                                            cache_subdir='models')\n",
        "\n",
        "                model.load_weights(weights_path)\n",
        "\n",
        "                if K.backend() == 'tensorflow':\n",
        "                    warnings.warn('You are using the TensorFlow backend, yet you '\n",
        "                                  'are using the Theano '\n",
        "                                  'image dimension ordering convention '\n",
        "                                  '(`image_dim_ordering=\"th\"`). '\n",
        "                                  'For best performance, set '\n",
        "                                  '`image_dim_ordering=\"tf\"` in '\n",
        "                                  'your Keras config '\n",
        "                                  'at ~/.keras/keras.json.')\n",
        "                    convert_all_kernels_in_model(model)\n",
        "            else:\n",
        "                if include_top:\n",
        "                    h5_file = 'wide_resnet_28_8_tf_dim_ordering_tf_kernels.h5'\n",
        "                    weights_path = get_file(h5_file,\n",
        "                                            TF_WEIGHTS_PATH,\n",
        "                                            cache_subdir='models')\n",
        "                else:\n",
        "                    h5_file = 'wide_resnet_28_8_tf_dim_ordering_tf_kernels_no_top.h5'\n",
        "                    weights_path = get_file(h5_file,\n",
        "                                            TF_WEIGHTS_PATH_NO_TOP,\n",
        "                                            cache_subdir='models')\n",
        "\n",
        "                model.load_weights(weights_path)\n",
        "\n",
        "                if K.backend() == 'theano':\n",
        "                    convert_all_kernels_in_model(model)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XocORwFNuqBW"
      },
      "source": [
        "def __conv1_block(input):\n",
        "    x = Conv2D(16, (3, 3), padding='same')(input)\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gWRJewyut5o"
      },
      "source": [
        "def __conv2_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "    # Check if input number of filters is same as 16 * k, else create\n",
        "    # convolution2d for this input\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        if init.shape[1] != 16 * k:\n",
        "            init = Conv2D(16 * k, (1, 1), activation='linear', padding='same')(init)\n",
        "    else:\n",
        "        if init.shape[-1] != 16 * k:\n",
        "            init = Conv2D(16 * k, (1, 1), activation='linear', padding='same')(init)\n",
        "\n",
        "    x = Conv2D(16 * k, (3, 3), padding='same')(input)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    if dropout > 0.0:\n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    x = Conv2D(16 * k, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    m = add([init, x])\n",
        "    return m"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFy6tdc0STtb"
      },
      "source": [
        "def __conv3_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1\n",
        "\n",
        "    # Check if input number of filters is same as 32 * k, else\n",
        "    # create convolution2d for this input\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        if init.shape[1] != 32 * k:\n",
        "            init = Conv2D(32 * k, (1, 1), activation='linear', padding='same')(init)\n",
        "    else:\n",
        "        if init.shape[-1] != 32 * k:\n",
        "            init = Conv2D(32 * k, (1, 1), activation='linear', padding='same')(init)\n",
        "\n",
        "    x = Conv2D(32 * k, (3, 3), padding='same')(input)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    if dropout > 0.0:\n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    x = Conv2D(32 * k, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    m = add([init, x])\n",
        "    return m"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4M-TpcKvhiS"
      },
      "source": [
        "def ___conv4_block(input, k=1, dropout=0.0):\n",
        "    init = input\n",
        "\n",
        "    channel_axis = 1 if K.image_data_format() == 'th' else -1\n",
        "\n",
        "    # Check if input number of filters is same as 64 * k, else\n",
        "    # create convolution2d for this input\n",
        "    if K.image_data_format() == 'th':\n",
        "        if init.shape[1] != 64 * k:\n",
        "            init = Conv2D(64 * k, (1, 1), activation='linear', padding='same')(init)\n",
        "    else:\n",
        "        if init.shape[-1] != 64 * k:\n",
        "            init = Conv2D(64 * k, (1, 1), activation='linear', padding='same')(init)\n",
        "\n",
        "    x = Conv2D(64 * k, (3, 3), padding='same')(input)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    if dropout > 0.0:\n",
        "        x = Dropout(dropout)(x)\n",
        "\n",
        "    x = Conv2D(64 * k, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization(axis=channel_axis)(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    m = add([init, x])\n",
        "    return m"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUq-_yZ_vnBS"
      },
      "source": [
        "def __create_wide_residual_network(nb_classes, img_input, include_top, depth=28,\n",
        "                                   width=8, dropout=0.0, activation='softmax'):\n",
        "    ''' Creates a Wide Residual Network with specified parameters\n",
        "    Args:\n",
        "        nb_classes: Number of output classes\n",
        "        img_input: Input tensor or layer\n",
        "        include_top: Flag to include the last dense layer\n",
        "        depth: Depth of the network. Compute N = (n - 4) / 6.\n",
        "               For a depth of 16, n = 16, N = (16 - 4) / 6 = 2\n",
        "               For a depth of 28, n = 28, N = (28 - 4) / 6 = 4\n",
        "               For a depth of 40, n = 40, N = (40 - 4) / 6 = 6\n",
        "        width: Width of the network.\n",
        "        dropout: Adds dropout if value is greater than 0.0\n",
        "    Returns:a Keras Model\n",
        "    '''\n",
        "\n",
        "    N = (depth - 4) // 6\n",
        "\n",
        "    x = __conv1_block(img_input)\n",
        "    nb_conv = 4\n",
        "\n",
        "    for i in range(N):\n",
        "        x = __conv2_block(x, width, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    for i in range(N):\n",
        "        x = __conv3_block(x, width, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "    for i in range(N):\n",
        "        x = ___conv4_block(x, width, dropout)\n",
        "        nb_conv += 2\n",
        "\n",
        "    if include_top:\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Dense(nb_classes, activation=activation)(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF5v2bpcwZCy",
        "outputId": "d8b066bd-effa-4a60-ca30-48ad6ad85a1d"
      },
      "source": [
        "model = WideResidualNetwork()\n",
        "model.summary()"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"wide-resnet\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_152 (Conv2D)             (None, 32, 32, 16)   448         input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_136 (BatchN (None, 32, 32, 16)   64          conv2d_152[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_136 (Activation)     (None, 32, 32, 16)   0           batch_normalization_136[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_154 (Conv2D)             (None, 32, 32, 128)  18560       activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_137 (BatchN (None, 32, 32, 128)  512         conv2d_154[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_137 (Activation)     (None, 32, 32, 128)  0           batch_normalization_137[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_155 (Conv2D)             (None, 32, 32, 128)  147584      activation_137[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_138 (BatchN (None, 32, 32, 128)  512         conv2d_155[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_153 (Conv2D)             (None, 32, 32, 128)  2176        activation_136[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_138 (Activation)     (None, 32, 32, 128)  0           batch_normalization_138[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_64 (Add)                    (None, 32, 32, 128)  0           conv2d_153[0][0]                 \n",
            "                                                                 activation_138[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_156 (Conv2D)             (None, 32, 32, 128)  147584      add_64[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_139 (BatchN (None, 32, 32, 128)  512         conv2d_156[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_139 (Activation)     (None, 32, 32, 128)  0           batch_normalization_139[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_157 (Conv2D)             (None, 32, 32, 128)  147584      activation_139[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_140 (BatchN (None, 32, 32, 128)  512         conv2d_157[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_140 (Activation)     (None, 32, 32, 128)  0           batch_normalization_140[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_65 (Add)                    (None, 32, 32, 128)  0           add_64[0][0]                     \n",
            "                                                                 activation_140[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_158 (Conv2D)             (None, 32, 32, 128)  147584      add_65[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_141 (BatchN (None, 32, 32, 128)  512         conv2d_158[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_141 (Activation)     (None, 32, 32, 128)  0           batch_normalization_141[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_159 (Conv2D)             (None, 32, 32, 128)  147584      activation_141[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_142 (BatchN (None, 32, 32, 128)  512         conv2d_159[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_142 (Activation)     (None, 32, 32, 128)  0           batch_normalization_142[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_66 (Add)                    (None, 32, 32, 128)  0           add_65[0][0]                     \n",
            "                                                                 activation_142[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_160 (Conv2D)             (None, 32, 32, 128)  147584      add_66[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_143 (BatchN (None, 32, 32, 128)  512         conv2d_160[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_143 (Activation)     (None, 32, 32, 128)  0           batch_normalization_143[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_161 (Conv2D)             (None, 32, 32, 128)  147584      activation_143[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_144 (BatchN (None, 32, 32, 128)  512         conv2d_161[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_144 (Activation)     (None, 32, 32, 128)  0           batch_normalization_144[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_67 (Add)                    (None, 32, 32, 128)  0           add_66[0][0]                     \n",
            "                                                                 activation_144[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 16, 16, 128)  0           add_67[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_163 (Conv2D)             (None, 16, 16, 256)  295168      max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_145 (BatchN (None, 16, 16, 256)  1024        conv2d_163[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_145 (Activation)     (None, 16, 16, 256)  0           batch_normalization_145[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_164 (Conv2D)             (None, 16, 16, 256)  590080      activation_145[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_146 (BatchN (None, 16, 16, 256)  1024        conv2d_164[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_162 (Conv2D)             (None, 16, 16, 256)  33024       max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_146 (Activation)     (None, 16, 16, 256)  0           batch_normalization_146[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_68 (Add)                    (None, 16, 16, 256)  0           conv2d_162[0][0]                 \n",
            "                                                                 activation_146[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_165 (Conv2D)             (None, 16, 16, 256)  590080      add_68[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_147 (BatchN (None, 16, 16, 256)  1024        conv2d_165[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_147 (Activation)     (None, 16, 16, 256)  0           batch_normalization_147[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_166 (Conv2D)             (None, 16, 16, 256)  590080      activation_147[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_148 (BatchN (None, 16, 16, 256)  1024        conv2d_166[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_148 (Activation)     (None, 16, 16, 256)  0           batch_normalization_148[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_69 (Add)                    (None, 16, 16, 256)  0           add_68[0][0]                     \n",
            "                                                                 activation_148[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_167 (Conv2D)             (None, 16, 16, 256)  590080      add_69[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_149 (BatchN (None, 16, 16, 256)  1024        conv2d_167[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_149 (Activation)     (None, 16, 16, 256)  0           batch_normalization_149[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_168 (Conv2D)             (None, 16, 16, 256)  590080      activation_149[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_150 (BatchN (None, 16, 16, 256)  1024        conv2d_168[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_150 (Activation)     (None, 16, 16, 256)  0           batch_normalization_150[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_70 (Add)                    (None, 16, 16, 256)  0           add_69[0][0]                     \n",
            "                                                                 activation_150[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_169 (Conv2D)             (None, 16, 16, 256)  590080      add_70[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_151 (BatchN (None, 16, 16, 256)  1024        conv2d_169[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_151 (Activation)     (None, 16, 16, 256)  0           batch_normalization_151[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_170 (Conv2D)             (None, 16, 16, 256)  590080      activation_151[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_152 (BatchN (None, 16, 16, 256)  1024        conv2d_170[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_152 (Activation)     (None, 16, 16, 256)  0           batch_normalization_152[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_71 (Add)                    (None, 16, 16, 256)  0           add_70[0][0]                     \n",
            "                                                                 activation_152[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling2D) (None, 8, 8, 256)    0           add_71[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_172 (Conv2D)             (None, 8, 8, 512)    1180160     max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_153 (BatchN (None, 8, 8, 512)    2048        conv2d_172[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_153 (Activation)     (None, 8, 8, 512)    0           batch_normalization_153[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_173 (Conv2D)             (None, 8, 8, 512)    2359808     activation_153[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_154 (BatchN (None, 8, 8, 512)    2048        conv2d_173[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_171 (Conv2D)             (None, 8, 8, 512)    131584      max_pooling2d_14[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation_154 (Activation)     (None, 8, 8, 512)    0           batch_normalization_154[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_72 (Add)                    (None, 8, 8, 512)    0           conv2d_171[0][0]                 \n",
            "                                                                 activation_154[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_174 (Conv2D)             (None, 8, 8, 512)    2359808     add_72[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_155 (BatchN (None, 8, 8, 512)    2048        conv2d_174[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_155 (Activation)     (None, 8, 8, 512)    0           batch_normalization_155[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_175 (Conv2D)             (None, 8, 8, 512)    2359808     activation_155[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_156 (BatchN (None, 8, 8, 512)    2048        conv2d_175[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_156 (Activation)     (None, 8, 8, 512)    0           batch_normalization_156[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_73 (Add)                    (None, 8, 8, 512)    0           add_72[0][0]                     \n",
            "                                                                 activation_156[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_176 (Conv2D)             (None, 8, 8, 512)    2359808     add_73[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_157 (BatchN (None, 8, 8, 512)    2048        conv2d_176[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_157 (Activation)     (None, 8, 8, 512)    0           batch_normalization_157[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_177 (Conv2D)             (None, 8, 8, 512)    2359808     activation_157[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_158 (BatchN (None, 8, 8, 512)    2048        conv2d_177[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_158 (Activation)     (None, 8, 8, 512)    0           batch_normalization_158[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_74 (Add)                    (None, 8, 8, 512)    0           add_73[0][0]                     \n",
            "                                                                 activation_158[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_178 (Conv2D)             (None, 8, 8, 512)    2359808     add_74[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_159 (BatchN (None, 8, 8, 512)    2048        conv2d_178[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_159 (Activation)     (None, 8, 8, 512)    0           batch_normalization_159[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_179 (Conv2D)             (None, 8, 8, 512)    2359808     activation_159[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_160 (BatchN (None, 8, 8, 512)    2048        conv2d_179[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_160 (Activation)     (None, 8, 8, 512)    0           batch_normalization_160[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "add_75 (Add)                    (None, 8, 8, 512)    0           add_74[0][0]                     \n",
            "                                                                 activation_160[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 512)          0           add_75[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 10)           5130        global_average_pooling2d_3[0][0] \n",
            "==================================================================================================\n",
            "Total params: 23,377,290\n",
            "Trainable params: 23,362,922\n",
            "Non-trainable params: 14,368\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkDjl8exTTDZ"
      },
      "source": [
        "Define an optimizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTRuAT1FTTOw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e954de01-3baa-479d-800d-aee93dc18f72"
      },
      "source": [
        "opt = SGD(lr=0.1, decay=1e-6)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmhjZqVhfV18"
      },
      "source": [
        "DEFINE A LEARNING RATE SCHEDULER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjGe1KAwfV7F"
      },
      "source": [
        "def scheduler(epoch):\n",
        "    if epoch < 25:\n",
        "        return .1\n",
        "    elif epoch < 50:\n",
        "        return 0.01\n",
        "    else:\n",
        "        return 0.001\n",
        "\n",
        "# Callbacks\n",
        "set_lr = LRS(scheduler)\n",
        "es = keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHhBHWFjTTYy"
      },
      "source": [
        "Compile the model, define loss and link the optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W8KCPtcTTii"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBOKdV6MTTtA"
      },
      "source": [
        "Finally, train the model and evaluate over the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLPsSdVDTT37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b36995-6ef3-4276-9920-2829a00f9441"
      },
      "source": [
        "history=model.fit(datagen.flow(x_train, y_train,batch_size=batch_size),\n",
        "                  steps_per_epoch=len(x_train) / batch_size, \n",
        "                  epochs=epochs,\n",
        "                  validation_data=(x_test, y_test),\n",
        "                  callbacks=[set_lr, es],\n",
        "                  verbose=1)\n",
        "\n",
        "# Evaluate over test\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "478/500 [===========================>..] - ETA: 7s - loss: 0.7996 - accuracy: 0.7597"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_oBDiZbbO0G"
      },
      "source": [
        "print(history.history.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4uLWmxCbaq9"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wlYhPH9bcz9"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}